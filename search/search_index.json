{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Penambangan Web web crawler Assalamualaikum WR. WB Nama :Moh Iqbal Okthapian NIM :160411100108 Mata kuliah : Penambangan dan Pencarian Web - 2019 Jurusan : Teknik Informatika Perguruan Tinggi : Universitas Trunojoyo Madura Pada kesampatan kali ini akan dijelaskan mengenai web crawler Apa itu web crawler ? Yang Diperlukan Bahasa Python, dengan library: BeautifulSoup4 ( install menggunakan pip ) requests (install menggunakan pip ) SQLite3 (library bawaan python) csv (library bawaan python) numpy ( install menggunakan pip ) scipy ( install menggunakan pip scikit-learn ( install menggunakan pip , perlu untuk install numpy dan scipy terlebih dulu) Scikit-fuzzy ( install menggunakan pip , perlu untuk install numpy dan scipy terlebih dulu) Pengertian Web crawler adalah suatu program atau script otomat yang relatif simple, yang dengan metode tertentu melakukan scan atau \u201ccrawl\u201d ke semua halaman-halaman Internet untuk membuat index dari data yang dicarinya. Nama lain untuk web crawl adalah web spider, web robot, bot, crawl dan automatic indexer. Web crawl dapat digunakan untuk beragam tujuan. Penggunaan yang paling umum adalah yang terkait dengan search engine. Search engine menggunakan web crawl untuk mengumpulkan informasi mengenai apa yang ada di halaman-halaman web publik. Tujuan utamanya adalah mengumpukan data sehingga ketika pengguna Internet mengetikkan kata pencarian di komputernya, search engine dapat dengan segera menampilkan web site yang relevan. Karena untuk crawler kita butuh link ,maka langkah pertama adalah kita tentukan dahulu link yang akan kita crawler Pada kasus ini saya menggunakan link : https://www.suara.com/news/news-category/internasional Diatas adalah tampilan webnya. Langkah selanjutnya adalah kita mencari tahu artikel tersebut ada diantara tag apa, maka kita perlu inspect element HTMLnya Untuk tag per artikel sudah ditemukan yaitu pada tag li dengan class=\u201d item-outer\u201d dan untuk judulnya ada di tag h4 dengan class=\u201dpast-title\u201d Maka kodenya adalah: html=urlopen(\"https://www.suara.com/news/news-category/internasional\").read() soup=BeautifulSoup(html,\"lxml\") ar= soup.find_all(\"li\",\"item-outer\") i=1 judul=[] for j in ar: dapat_judul=j.find('h4','post-title').get_text().replace(\"\\n\",\"\") judul.append(dapat_judul) print(judul) Kode diatas kita sudah mendapatkan judulnya, lalu kita akan mendapatkan deskripsi dari artikelnya , caranya sama seperti kode diatas namun kita harus mendapatan linknya tiap artikel terlebih dahulu links = [] deskripsifull=[] for link in soup.findAll('a','ellipsis2'): links.append(link.get('href')) #menyimpan link print(links) Diatas untuk linknya berada di dalam tag a dan dengan class 'ellipsis2' , berbeda dengan cara sebelumnya kali ini kita mengambil linknya menggunkan link.get('href')) Kita kan mengambil deskripsi tiap artikel , caranya sama seperti langkah awal namun dalam hal ini kita berikan perulangan sesuai judul yang kita crawl , dan di ambil deskripsinya satu satupersatu des=[] for i in links: deslink=urlopen(i).read() #membuka link 1per1 soup1=BeautifulSoup(deslink,\"lxml\") ketdes= soup1.find_all(\"article\") da=[] for j in ketdes: desk=\"\" konten= soup1.find_all('article','content-article') for i in soup1.find('article','content-article').find_all('p'): desk=desk+i.text if(not desk in des): des.append(desk) if(not desk in des): des.append(desk) Kode diatas digunakan agar jika ada kesalahan saat crawl ,missal ada data yang sama maka data tidak akan dimasukkan ,jadi hanya mengambil data yang berbeda saja tiap artikel dan saya tampung di Array . Karena pada data juga ada karakter yang tidak penting missal, jarak spasi yang terlalu panjang ,atau baris yang terlalu lebar,bias juga tanda petik,dll maka diperlukan perbaikan: print(len(des)) for j in des: print(j.replace('\"',' ').replace('.',' ').replace('/',' ').replace(',',' ').replace('\"\"',' ')) print(\"==========================================\") Setelah data judul sudah didapatkan sekarang kita buat menjadi file exel data = pd.read_csv(\"dataku.csv\") # Preview the first 5 lines of the loaded data deskr=[] for i in data['deskripsi']: deskr.append(i) print(deskr) Pada penjelasan disatas dapat disimpulkan bahwa untuk crawl alurnya seperti ini: Setelah kita mendapatkan datanya lalu kita melakukan Text Prosesing .","title":"Pengenalan"},{"location":"#web-crawler","text":"Assalamualaikum WR. WB Nama :Moh Iqbal Okthapian NIM :160411100108 Mata kuliah : Penambangan dan Pencarian Web - 2019 Jurusan : Teknik Informatika Perguruan Tinggi : Universitas Trunojoyo Madura Pada kesampatan kali ini akan dijelaskan mengenai web crawler Apa itu web crawler ?","title":"web crawler"},{"location":"#yang-diperlukan","text":"Bahasa Python, dengan library: BeautifulSoup4 ( install menggunakan pip ) requests (install menggunakan pip ) SQLite3 (library bawaan python) csv (library bawaan python) numpy ( install menggunakan pip ) scipy ( install menggunakan pip scikit-learn ( install menggunakan pip , perlu untuk install numpy dan scipy terlebih dulu) Scikit-fuzzy ( install menggunakan pip , perlu untuk install numpy dan scipy terlebih dulu)","title":"Yang Diperlukan"},{"location":"#pengertian","text":"Web crawler adalah suatu program atau script otomat yang relatif simple, yang dengan metode tertentu melakukan scan atau \u201ccrawl\u201d ke semua halaman-halaman Internet untuk membuat index dari data yang dicarinya. Nama lain untuk web crawl adalah web spider, web robot, bot, crawl dan automatic indexer. Web crawl dapat digunakan untuk beragam tujuan. Penggunaan yang paling umum adalah yang terkait dengan search engine. Search engine menggunakan web crawl untuk mengumpulkan informasi mengenai apa yang ada di halaman-halaman web publik. Tujuan utamanya adalah mengumpukan data sehingga ketika pengguna Internet mengetikkan kata pencarian di komputernya, search engine dapat dengan segera menampilkan web site yang relevan. Karena untuk crawler kita butuh link ,maka langkah pertama adalah kita tentukan dahulu link yang akan kita crawler Pada kasus ini saya menggunakan link : https://www.suara.com/news/news-category/internasional Diatas adalah tampilan webnya. Langkah selanjutnya adalah kita mencari tahu artikel tersebut ada diantara tag apa, maka kita perlu inspect element HTMLnya Untuk tag per artikel sudah ditemukan yaitu pada tag li dengan class=\u201d item-outer\u201d dan untuk judulnya ada di tag h4 dengan class=\u201dpast-title\u201d Maka kodenya adalah: html=urlopen(\"https://www.suara.com/news/news-category/internasional\").read() soup=BeautifulSoup(html,\"lxml\") ar= soup.find_all(\"li\",\"item-outer\") i=1 judul=[] for j in ar: dapat_judul=j.find('h4','post-title').get_text().replace(\"\\n\",\"\") judul.append(dapat_judul) print(judul) Kode diatas kita sudah mendapatkan judulnya, lalu kita akan mendapatkan deskripsi dari artikelnya , caranya sama seperti kode diatas namun kita harus mendapatan linknya tiap artikel terlebih dahulu links = [] deskripsifull=[] for link in soup.findAll('a','ellipsis2'): links.append(link.get('href')) #menyimpan link print(links) Diatas untuk linknya berada di dalam tag a dan dengan class 'ellipsis2' , berbeda dengan cara sebelumnya kali ini kita mengambil linknya menggunkan link.get('href')) Kita kan mengambil deskripsi tiap artikel , caranya sama seperti langkah awal namun dalam hal ini kita berikan perulangan sesuai judul yang kita crawl , dan di ambil deskripsinya satu satupersatu des=[] for i in links: deslink=urlopen(i).read() #membuka link 1per1 soup1=BeautifulSoup(deslink,\"lxml\") ketdes= soup1.find_all(\"article\") da=[] for j in ketdes: desk=\"\" konten= soup1.find_all('article','content-article') for i in soup1.find('article','content-article').find_all('p'): desk=desk+i.text if(not desk in des): des.append(desk) if(not desk in des): des.append(desk) Kode diatas digunakan agar jika ada kesalahan saat crawl ,missal ada data yang sama maka data tidak akan dimasukkan ,jadi hanya mengambil data yang berbeda saja tiap artikel dan saya tampung di Array . Karena pada data juga ada karakter yang tidak penting missal, jarak spasi yang terlalu panjang ,atau baris yang terlalu lebar,bias juga tanda petik,dll maka diperlukan perbaikan: print(len(des)) for j in des: print(j.replace('\"',' ').replace('.',' ').replace('/',' ').replace(',',' ').replace('\"\"',' ')) print(\"==========================================\") Setelah data judul sudah didapatkan sekarang kita buat menjadi file exel data = pd.read_csv(\"dataku.csv\") # Preview the first 5 lines of the loaded data deskr=[] for i in data['deskripsi']: deskr.append(i) print(deskr) Pada penjelasan disatas dapat disimpulkan bahwa untuk crawl alurnya seperti ini: Setelah kita mendapatkan datanya lalu kita melakukan Text Prosesing .","title":"Pengertian"},{"location":"authors-notes/","text":"Author's notes Hi, I'm Martin ( @squidfunk ) I'm a freelance polyglot software engineer and entrepreneur from Cologne, Germany with more than 12 years of experience in full-stack web development and system programming. If you're interested in my projects, please see my CV . Why another theme? Some time ago I wanted to release a project to the open, but it was in need of user documentation. I checked out the available tools and stuck with MkDocs, because it was so simple and easy to use. However, none of the available themes convinced me. I wanted to build something that was usable on all screen sizes from the ground up, something beautiful and practical at the same time. Google's Material Design appeared to be the perfect fit and this something became Material, a Material Design theme for MkDocs.","title":"Author's notes"},{"location":"authors-notes/#authors-notes","text":"","title":"Author's notes"},{"location":"authors-notes/#hi-im-martin-squidfunk","text":"I'm a freelance polyglot software engineer and entrepreneur from Cologne, Germany with more than 12 years of experience in full-stack web development and system programming. If you're interested in my projects, please see my CV .","title":"Hi, I'm Martin (@squidfunk)"},{"location":"authors-notes/#why-another-theme","text":"Some time ago I wanted to release a project to the open, but it was in need of user documentation. I checked out the available tools and stuck with MkDocs, because it was so simple and easy to use. However, none of the available themes convinced me. I wanted to build something that was usable on all screen sizes from the ground up, something beautiful and practical at the same time. Google's Material Design appeared to be the perfect fit and this something became Material, a Material Design theme for MkDocs.","title":"Why another theme?"},{"location":"compliance/","text":"Preprocessing Tahap preprocessing merupakan tahap mengolah data agar data lebih mudah diproses. Untuk teman-teman tidak diharuskan mengunakaan python saja, namun terserah teman-teman Tpi pada penejalasan ini saya menggunakan python Seleksi Fitur Seleksi fitur merupakan salah satu cara untuk mengurangi dimensi fitur yang sangat banyak. Seperti pada kasus kita, Text Mining, jumlah fitur yang didapatkan bisa mencapai lebih dari 2000 kata yang berbeda. Namun, tidak semua kata tersebut benar-benar berpengaruh pada hasil akhir nantinya. Selain itu, kita tahu bahwa semakin banyak data yang diproses, maka lebih banyak biaya dan waktu yang digunakan untuk memprosesnya. Oleh karena itu, kita perlu melakukan pengurangan fitur tanpa mengurangi kualitas hasil akhir, misalnya dengan Seleksi Fitur. Pada dasarnya, seleksi fitur memiliki 3 tipe umum: Wrap Filter Embed def seleksiFiturPearson(data, threshold): global meanFitur meanFitur = meanF(data) u=0 while u < len(data[0]): dataBaru=data[:, :u+1] meanBaru=meanFitur[:u+1] v = u while v < len(data[0]): if u != v: value = pearsonCalculate(data, u,v) if value < threshold: dataBaru = np.hstack((dataBaru, data[:, v].reshape(data.shape[0],1))) meanBaru = np.hstack((meanBaru, meanFitur[v])) v+=1 data = dataBaru meanFitur=meanBaru if u%50 == 0 : print(u, data.shape) u+=1 return data Selain itu, Seleksi Fitur juga memiliki banyak sekali metode-metode, seperti Information Gain, Chi Square, Pearson, dll. pearson Correlation Pendekatan Pearson merupakan pendekatan paling sederhana. Pada pendekatan ini, setiap fitur akan dihitung korelasinya. Semakin tinggi nilainya, maka fitur tersebut semakin kuat korelasinya. Lalu fitur yang memiliki korelasi tinggi akan dibuang salah satunya. Pendekatan ini digunakan untuk data tipe numerik. Kodenya bisa dilihat dibawah ini def pearsonCalculate(data, u,v): \"i, j is an index\" atas=0; bawah_kiri=0; bawah_kanan = 0 for k in range(len(data)): atas += (data[k,u] - meanFitur[u]) * (data[k,v] - meanFitur[v]) bawah_kiri += (data[k,u] - meanFitur[u])**2 bawah_kanan += (data[k,v] - meanFitur[v])**2 bawah_kiri = bawah_kiri ** 0.5 bawah_kanan = bawah_kanan ** 0.5 return atas/(bawah_kiri * bawah_kanan) def meanF(data): meanFitur=[] for i in range(len(data[0])): meanFitur.append(sum(data[:,i])/len(data)) return np.array(meanFitur) Clustering Clustering merupakan pengelompokan data menjadi k-kelompok (dengan k merupakan banyak kelompok). Pengelompkan tersebut berdasarkan ciri yang mirip. Pada kasus ini, maka ciri yang mirip bisa diketahui dari kata yang menjadi ciri dari setiap dokumen. Metode Clustering sendiri ada banyak. Salah duanya adalah K-Means Clustering dan Fuzzy C-Means Clustering. Setelah dilakukan proses Clustering, perlu kita cari nilai Silhouette Coefficient untuk melihat apakah hasil cluster tersebut sudah bagus atau tidak. K-Means # Clustering kmeans = KMeans(n_clusters=5, random_state=0).fit(tfidf_matrix.todense()) for i in range(len(kmeans.labels_)): print(\"Doc %d =>> cluster %d\" %(i+1, kmeans.labels_[i])) Code di atas adalah code untuk melakukan clustering. Pada contoh ini cluster dibagi menjadi 5. Banyak cluster bisa diubah sesuai kebutuhan. Klasifikasi Berbeda dengan Clustering yang mengelompokkan data, klasifikasi lebih mirip pada peramalan data dengan merujuk kategori. Contoh simplenya, seperti peramalan golf. Jika cuaca cerah, angin tidak kencang, maka akan diadakan pertandingan golf. Jika cuaca cerah tapi angin kencang, maka pertandingan golf dibatalkan. Proses ini biasanya memerlukan data latih dan data test. Untuk menguji keberhasilannya, diperlukan untuk menghitung akurasi atau confution matrix. Metode-metode yang sering dipakai untuk klasifikasi di antaranya Naive Bayes. parameter dari fuzzy c-means berturut-turut : data, jumlahCluster, pembobot, erorMaksimal, serta IterasiMaksimal. Naive Bayes Naive bayes termasuk pada supervised learning berdasarkan teorema Bayes, dengan asumsi \"naive\", bahwa setiap fitur tidak saling terkait (independen). Terdapat beberapa jenis Naive Bayes, seperti Gaussian NB, Multinomial NB, dll. Namun pada kasus text classification, Multinomial lebih cocok digunakan. Sebelum itu, kita perlu membagi data menjadi dua bagian: data training, dan data test x_train, x_test, y_train, y_test = train_test_split(xBaru1, label, test_size=0.33, random_state=0) model = MultinomialNB().fit(x_train, y_train) predicted = model.predict(x_test)","title":"Preprocessing"},{"location":"compliance/#preprocessing","text":"Tahap preprocessing merupakan tahap mengolah data agar data lebih mudah diproses. Untuk teman-teman tidak diharuskan mengunakaan python saja, namun terserah teman-teman Tpi pada penejalasan ini saya menggunakan python","title":"Preprocessing"},{"location":"compliance/#seleksi-fitur","text":"Seleksi fitur merupakan salah satu cara untuk mengurangi dimensi fitur yang sangat banyak. Seperti pada kasus kita, Text Mining, jumlah fitur yang didapatkan bisa mencapai lebih dari 2000 kata yang berbeda. Namun, tidak semua kata tersebut benar-benar berpengaruh pada hasil akhir nantinya. Selain itu, kita tahu bahwa semakin banyak data yang diproses, maka lebih banyak biaya dan waktu yang digunakan untuk memprosesnya. Oleh karena itu, kita perlu melakukan pengurangan fitur tanpa mengurangi kualitas hasil akhir, misalnya dengan Seleksi Fitur. Pada dasarnya, seleksi fitur memiliki 3 tipe umum: Wrap Filter Embed def seleksiFiturPearson(data, threshold): global meanFitur meanFitur = meanF(data) u=0 while u < len(data[0]): dataBaru=data[:, :u+1] meanBaru=meanFitur[:u+1] v = u while v < len(data[0]): if u != v: value = pearsonCalculate(data, u,v) if value < threshold: dataBaru = np.hstack((dataBaru, data[:, v].reshape(data.shape[0],1))) meanBaru = np.hstack((meanBaru, meanFitur[v])) v+=1 data = dataBaru meanFitur=meanBaru if u%50 == 0 : print(u, data.shape) u+=1 return data Selain itu, Seleksi Fitur juga memiliki banyak sekali metode-metode, seperti Information Gain, Chi Square, Pearson, dll.","title":"Seleksi Fitur"},{"location":"compliance/#pearson-correlation","text":"Pendekatan Pearson merupakan pendekatan paling sederhana. Pada pendekatan ini, setiap fitur akan dihitung korelasinya. Semakin tinggi nilainya, maka fitur tersebut semakin kuat korelasinya. Lalu fitur yang memiliki korelasi tinggi akan dibuang salah satunya. Pendekatan ini digunakan untuk data tipe numerik. Kodenya bisa dilihat dibawah ini def pearsonCalculate(data, u,v): \"i, j is an index\" atas=0; bawah_kiri=0; bawah_kanan = 0 for k in range(len(data)): atas += (data[k,u] - meanFitur[u]) * (data[k,v] - meanFitur[v]) bawah_kiri += (data[k,u] - meanFitur[u])**2 bawah_kanan += (data[k,v] - meanFitur[v])**2 bawah_kiri = bawah_kiri ** 0.5 bawah_kanan = bawah_kanan ** 0.5 return atas/(bawah_kiri * bawah_kanan) def meanF(data): meanFitur=[] for i in range(len(data[0])): meanFitur.append(sum(data[:,i])/len(data)) return np.array(meanFitur)","title":"pearson Correlation"},{"location":"compliance/#clustering","text":"Clustering merupakan pengelompokan data menjadi k-kelompok (dengan k merupakan banyak kelompok). Pengelompkan tersebut berdasarkan ciri yang mirip. Pada kasus ini, maka ciri yang mirip bisa diketahui dari kata yang menjadi ciri dari setiap dokumen. Metode Clustering sendiri ada banyak. Salah duanya adalah K-Means Clustering dan Fuzzy C-Means Clustering. Setelah dilakukan proses Clustering, perlu kita cari nilai Silhouette Coefficient untuk melihat apakah hasil cluster tersebut sudah bagus atau tidak.","title":"Clustering"},{"location":"compliance/#k-means","text":"# Clustering kmeans = KMeans(n_clusters=5, random_state=0).fit(tfidf_matrix.todense()) for i in range(len(kmeans.labels_)): print(\"Doc %d =>> cluster %d\" %(i+1, kmeans.labels_[i])) Code di atas adalah code untuk melakukan clustering. Pada contoh ini cluster dibagi menjadi 5. Banyak cluster bisa diubah sesuai kebutuhan.","title":"K-Means"},{"location":"compliance/#klasifikasi","text":"Berbeda dengan Clustering yang mengelompokkan data, klasifikasi lebih mirip pada peramalan data dengan merujuk kategori. Contoh simplenya, seperti peramalan golf. Jika cuaca cerah, angin tidak kencang, maka akan diadakan pertandingan golf. Jika cuaca cerah tapi angin kencang, maka pertandingan golf dibatalkan. Proses ini biasanya memerlukan data latih dan data test. Untuk menguji keberhasilannya, diperlukan untuk menghitung akurasi atau confution matrix. Metode-metode yang sering dipakai untuk klasifikasi di antaranya Naive Bayes. parameter dari fuzzy c-means berturut-turut : data, jumlahCluster, pembobot, erorMaksimal, serta IterasiMaksimal.","title":"Klasifikasi"},{"location":"compliance/#naive-bayes","text":"Naive bayes termasuk pada supervised learning berdasarkan teorema Bayes, dengan asumsi \"naive\", bahwa setiap fitur tidak saling terkait (independen). Terdapat beberapa jenis Naive Bayes, seperti Gaussian NB, Multinomial NB, dll. Namun pada kasus text classification, Multinomial lebih cocok digunakan. Sebelum itu, kita perlu membagi data menjadi dua bagian: data training, dan data test x_train, x_test, y_train, y_test = train_test_split(xBaru1, label, test_size=0.33, random_state=0) model = MultinomialNB().fit(x_train, y_train) predicted = model.predict(x_test)","title":"Naive Bayes"},{"location":"contributing/","text":"../CONTRIBUTING.md","title":"Contributing"},{"location":"customization/","text":"TF - IDF TF TF atau term frequency adalah weighting scheme yang digunakan untuk menentukan relevansi dokumen dengan sebuah query (term). TF menentukan bobot relevansi sebuah dokumen dan term berdasarkan frekuensi kemunculan term pada dokumen terkait. Untuk menghitung TF terdapat beberapa jenis fungsi yang dapat digunakan DF Jika TF adalah frekuensi kemunculan suatu term pada sebuah dokumen, DF merupakan jumlah dokumen dimana terdapat term yang bersangkutan. Konsep DF sendiri dilatarbelakangin oleh masalah pada TF, dimana semua term dianggap sama penting, sehingga term yang memiliki sedikit atau tidak memiliki discrimination power dapat mempengaruhi akurasi dalam menentukan relevansi antara term dan dokumen. Ide dari DF adalah dengan mengurangi bobot TF suatu term dengan membaginya dengan frekuensi term terhadap koleksi dokumen (DF). Jadi sebuah term yang memiliki bobot TF yang besar namun dengan bobot DF yang besar pula tidak akan memiliki pengaruh yang besar dalam menentukan sebuah relevansi . IDF IDF adalah inverse dari DF, IDF akan melakukan proses scaling pada TF. Term yang memiliki DF yang rendah akan memiliki IDF yang tinggi. Dengan kata lain, sebuah term yang jarang ditemui pada koleksi dokumen atau bisa dikatakan sebagai term khusus akan memiliki nilai IDF yang tinggi. Untuk menghitung IDF pada sebuah term pada sebuah koleksi dokumen dapat menggunakan fungsi dibawah ini, TF-IDF Selain menggunakan Bag of Words, kita juga bisa menggunakan metode TF-IDF. Hal ini karena Bag of Word memiliki kelemahan tersendiri. TF-IDF sendiri merupakan kepanjangan dari Term Frequence (frekuensi Kata) dan Invers Document Frequence (invers frekuensi Dokumen). Rumus TF-IDF sendiri terbilang mudah karena hanya TFxIDF. Kita telah mencari TF sebelumnya (yaitu Bag of Words), karena konsep keduanya yang memang sama. Sekarang kita tinggal mencari nilai IDF. Untuk mendapatkan IDF, pertama kita perlu mencari DF (frekuensi Dokumen). Contoh: Artikel 1:anak itu pergi kesekolah Artikel2:anak dan ibu pergi Kata Document yangmemiliki kata tersebut anak 2 ibu 1 dan 1 pergi 2 kesekolah 1 ibu 1 df = list() total_doc = bow.shape[0] for kolom in range(len(bow[0])): total = 0 for baris in range(len(bow)): if (bow[baris, kolom] > 0): total +=1 df.append(total) df = np.array(df) idf = list() for i in df: tmp = 1 + log10(total_doc/(1+i)) idf.append(tmp) idf = np.array(idf) tfidf = bow * idf Tahap selanjutnya adalah Preprocessing .","title":"TF - IDF"},{"location":"customization/#tf-idf","text":"","title":"TF - IDF"},{"location":"customization/#tf","text":"TF atau term frequency adalah weighting scheme yang digunakan untuk menentukan relevansi dokumen dengan sebuah query (term). TF menentukan bobot relevansi sebuah dokumen dan term berdasarkan frekuensi kemunculan term pada dokumen terkait. Untuk menghitung TF terdapat beberapa jenis fungsi yang dapat digunakan","title":"TF"},{"location":"customization/#df","text":"Jika TF adalah frekuensi kemunculan suatu term pada sebuah dokumen, DF merupakan jumlah dokumen dimana terdapat term yang bersangkutan. Konsep DF sendiri dilatarbelakangin oleh masalah pada TF, dimana semua term dianggap sama penting, sehingga term yang memiliki sedikit atau tidak memiliki discrimination power dapat mempengaruhi akurasi dalam menentukan relevansi antara term dan dokumen. Ide dari DF adalah dengan mengurangi bobot TF suatu term dengan membaginya dengan frekuensi term terhadap koleksi dokumen (DF). Jadi sebuah term yang memiliki bobot TF yang besar namun dengan bobot DF yang besar pula tidak akan memiliki pengaruh yang besar dalam menentukan sebuah relevansi .","title":"DF"},{"location":"customization/#idf","text":"IDF adalah inverse dari DF, IDF akan melakukan proses scaling pada TF. Term yang memiliki DF yang rendah akan memiliki IDF yang tinggi. Dengan kata lain, sebuah term yang jarang ditemui pada koleksi dokumen atau bisa dikatakan sebagai term khusus akan memiliki nilai IDF yang tinggi. Untuk menghitung IDF pada sebuah term pada sebuah koleksi dokumen dapat menggunakan fungsi dibawah ini,","title":"IDF"},{"location":"customization/#tf-idf_1","text":"Selain menggunakan Bag of Words, kita juga bisa menggunakan metode TF-IDF. Hal ini karena Bag of Word memiliki kelemahan tersendiri. TF-IDF sendiri merupakan kepanjangan dari Term Frequence (frekuensi Kata) dan Invers Document Frequence (invers frekuensi Dokumen). Rumus TF-IDF sendiri terbilang mudah karena hanya TFxIDF. Kita telah mencari TF sebelumnya (yaitu Bag of Words), karena konsep keduanya yang memang sama. Sekarang kita tinggal mencari nilai IDF. Untuk mendapatkan IDF, pertama kita perlu mencari DF (frekuensi Dokumen). Contoh: Artikel 1:anak itu pergi kesekolah Artikel2:anak dan ibu pergi Kata Document yangmemiliki kata tersebut anak 2 ibu 1 dan 1 pergi 2 kesekolah 1 ibu 1 df = list() total_doc = bow.shape[0] for kolom in range(len(bow[0])): total = 0 for baris in range(len(bow)): if (bow[baris, kolom] > 0): total +=1 df.append(total) df = np.array(df) idf = list() for i in df: tmp = 1 + log10(total_doc/(1+i)) idf.append(tmp) idf = np.array(idf) tfidf = bow * idf Tahap selanjutnya adalah Preprocessing .","title":"TF-IDF"},{"location":"getting-started/","text":"Text Processing Tokenisasi(n-gram) Tokenisasi adalah proses untuk membagi teks yang dapat berupa kalimat, paragraf atau dokumen, menjadi token-token. Sebagai contoh, tokenisasi dari kalimat \" Pelajar Indonesia di China Ditemukan Tewas. \" menghasilkan enam token, yakni: \" Pelajar \", \" Indonesia \", \" di \", \" China \", \" Ditemukan \", \" Tewas \". Biasanya, yang menjadi acuan pemisah antar token adalah spasi dan tanda baca. Tokenisasi berguna untuk analisis teks lebih lanjut dan dipakai dalam ilmu linguistik. Filtering Tahap Filtering adalah tahap mengambil kata-kata penting dari hasil token. Bisa menggunakan algoritma stoplist (membuang kata kurang penting) atau wordlist (menyimpan kata penting). Stoplist/stopword adalah kata-kata yang tidak deskriptif yang dapat dibuang dalam pendekatan bag-of-words. Contoh stopwords adalah \u201cyang\u201d, \u201cdan\u201d, \u201cdi\u201d, \u201cdari\u201d dan seterusnya Stamming Stemming adalah proses pemetaan dan penguraian bentuk dari suatu kata menjadi bentuk kata dasarnya. Gampangnya, proses mengubah kata berimbuhan menjadi kata dasar Stemming (atau mungkin lebih tepatnya lemmatization?) adalah proses mengubah kata berimbuhan menjadi kata dasar. Aturan-aturan bahasa diterapkan untuk menanggalkan imbuhan-imbuhan itu. Stemming (atau mungkin lebih tepatnya lemmatization?) adalah proses mengubah kata berimbuhan menjadi kata dasar. Aturan-aturan bahasa diterapkan untuk menanggalkan imbuhan-imbuhan itu. Contohnya: membetulkan -> betul berpegangan -> pegang Ada banyak persoalan yang dihadapi pada proses stemming Bahasa Indonesia, di antaranya yaitu: Imbuhan pada Bahasa Indonesia cukup kompleks, terdiri dari: Prefiks, imbuhan di depan kata: ber-tiga Suffiks, imbuhan di akhir kata: makan-an Konfiks, imbuhan di depan dan di akhir kata: per-ubah-an Infiks, imbuhan di tengah kata: kemilau. Imbuhan dari bahasa asing: final-isasi, sosial-isasi Aturan perubahan prefiks, seperti (me-) menjadi (meng-, mem-, men-, meny-) Word-Sense Ambiguity (Ambiguitas Rasa Kata), yaitu satu kata dapat memiliki dua makna (seperti misalnya homonim), dan berasal dari kata dasar yang berbeda. Contohnya: Berikan -> Ber-ikan Berikan -> Beri-kan Overstemming Kata berikan berdasarkan aturan pemenggalan, dapat dipenggal menjadi Ber-i-kan. Menjadi kata dasar i. Untuk mencegah overstemming, algoritma membutuhkan daftar kata dasar. Jika kata yang dipenggal ada di kata dasar, hentikan proses pemenggalan. Understemming Mengecek -> menjadi meng-ecek, seharusnya menge-cek. Hal ini dapat disebabkan karena pada kamus kata dasar, ecek juga merupakan kata dasar. Ketergantungan terhadap kamus / daftar kata dasar Untuk mencegah overstemming, algoritma menjadi tergantung pada kata dasar. Adanya kekurangan atau kelebihan pada kata dasar dapat menyebabkan overstemming atau understemming. # tentukan lokasi file, nama file, dan inisialisasi csv f = open('datakufull.csv', 'r') reader = csv.reader(f) deskripsi=[]; #full deskripsi judul=[]; #fulljudul # membaca baris per baris jumlah=0 for row in reader: jumlah+=1; if jumlah!=1: judul.append(str(row[1])) deskripsi.append(str(row[2])) des_katadasar=[] for i in deskripsi: hasil = '' kata_per_artikel={} for j in i.split(): if j.isalpha(): stop = stopword.remove(j) stem = stemmer.stem(stop) hasil += stem+ ' ' des_katadasar.append(hasil) Kode diatas adalah untuk memisahkan kata dasar ,saya ambil per artikel lalu saya gunakan library sastrawi untuk mendapatkan kata dasar. Untuk alur dari program/penjelasan diatas adalah: Setelah kita melewati proses text processing selanjutnya kita akan membuat Vector Space Model (VSM) .","title":"Text Processing"},{"location":"getting-started/#text-processing","text":"","title":"Text Processing"},{"location":"getting-started/#tokenisasin-gram","text":"Tokenisasi adalah proses untuk membagi teks yang dapat berupa kalimat, paragraf atau dokumen, menjadi token-token. Sebagai contoh, tokenisasi dari kalimat \" Pelajar Indonesia di China Ditemukan Tewas. \" menghasilkan enam token, yakni: \" Pelajar \", \" Indonesia \", \" di \", \" China \", \" Ditemukan \", \" Tewas \". Biasanya, yang menjadi acuan pemisah antar token adalah spasi dan tanda baca. Tokenisasi berguna untuk analisis teks lebih lanjut dan dipakai dalam ilmu linguistik.","title":"Tokenisasi(n-gram)"},{"location":"getting-started/#filtering","text":"Tahap Filtering adalah tahap mengambil kata-kata penting dari hasil token. Bisa menggunakan algoritma stoplist (membuang kata kurang penting) atau wordlist (menyimpan kata penting). Stoplist/stopword adalah kata-kata yang tidak deskriptif yang dapat dibuang dalam pendekatan bag-of-words. Contoh stopwords adalah \u201cyang\u201d, \u201cdan\u201d, \u201cdi\u201d, \u201cdari\u201d dan seterusnya","title":"Filtering"},{"location":"getting-started/#stamming","text":"Stemming adalah proses pemetaan dan penguraian bentuk dari suatu kata menjadi bentuk kata dasarnya. Gampangnya, proses mengubah kata berimbuhan menjadi kata dasar Stemming (atau mungkin lebih tepatnya lemmatization?) adalah proses mengubah kata berimbuhan menjadi kata dasar. Aturan-aturan bahasa diterapkan untuk menanggalkan imbuhan-imbuhan itu. Stemming (atau mungkin lebih tepatnya lemmatization?) adalah proses mengubah kata berimbuhan menjadi kata dasar. Aturan-aturan bahasa diterapkan untuk menanggalkan imbuhan-imbuhan itu. Contohnya: membetulkan -> betul berpegangan -> pegang Ada banyak persoalan yang dihadapi pada proses stemming Bahasa Indonesia, di antaranya yaitu: Imbuhan pada Bahasa Indonesia cukup kompleks, terdiri dari: Prefiks, imbuhan di depan kata: ber-tiga Suffiks, imbuhan di akhir kata: makan-an Konfiks, imbuhan di depan dan di akhir kata: per-ubah-an Infiks, imbuhan di tengah kata: kemilau. Imbuhan dari bahasa asing: final-isasi, sosial-isasi Aturan perubahan prefiks, seperti (me-) menjadi (meng-, mem-, men-, meny-) Word-Sense Ambiguity (Ambiguitas Rasa Kata), yaitu satu kata dapat memiliki dua makna (seperti misalnya homonim), dan berasal dari kata dasar yang berbeda. Contohnya: Berikan -> Ber-ikan Berikan -> Beri-kan Overstemming Kata berikan berdasarkan aturan pemenggalan, dapat dipenggal menjadi Ber-i-kan. Menjadi kata dasar i. Untuk mencegah overstemming, algoritma membutuhkan daftar kata dasar. Jika kata yang dipenggal ada di kata dasar, hentikan proses pemenggalan. Understemming Mengecek -> menjadi meng-ecek, seharusnya menge-cek. Hal ini dapat disebabkan karena pada kamus kata dasar, ecek juga merupakan kata dasar. Ketergantungan terhadap kamus / daftar kata dasar Untuk mencegah overstemming, algoritma menjadi tergantung pada kata dasar. Adanya kekurangan atau kelebihan pada kata dasar dapat menyebabkan overstemming atau understemming. # tentukan lokasi file, nama file, dan inisialisasi csv f = open('datakufull.csv', 'r') reader = csv.reader(f) deskripsi=[]; #full deskripsi judul=[]; #fulljudul # membaca baris per baris jumlah=0 for row in reader: jumlah+=1; if jumlah!=1: judul.append(str(row[1])) deskripsi.append(str(row[2])) des_katadasar=[] for i in deskripsi: hasil = '' kata_per_artikel={} for j in i.split(): if j.isalpha(): stop = stopword.remove(j) stem = stemmer.stem(stop) hasil += stem+ ' ' des_katadasar.append(hasil) Kode diatas adalah untuk memisahkan kata dasar ,saya ambil per artikel lalu saya gunakan library sastrawi untuk mendapatkan kata dasar. Untuk alur dari program/penjelasan diatas adalah: Setelah kita melewati proses text processing selanjutnya kita akan membuat Vector Space Model (VSM) .","title":"Stamming"},{"location":"license/","text":"License MIT License Copyright \u00a9 2016 - 2019 Martin Donath Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#license","text":"MIT License Copyright \u00a9 2016 - 2019 Martin Donath Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"release-notes/","text":"Referensi https://informatikalogi.com/text-preprocessing/ https://github.com/sastrawi/sastrawi/wiki/Stemming-Bahasa-Indonesia https://www.codepolitan.com/stemming-word-dalam-carik-bot-59a9ef6e96088 http://id.dbpedia.org/page/Tokenisasi https://www.suara.com/news/news-category/internasional Download kode full klik","title":"Referensi"},{"location":"release-notes/#referensi","text":"https://informatikalogi.com/text-preprocessing/ https://github.com/sastrawi/sastrawi/wiki/Stemming-Bahasa-Indonesia https://www.codepolitan.com/stemming-word-dalam-carik-bot-59a9ef6e96088 http://id.dbpedia.org/page/Tokenisasi https://www.suara.com/news/news-category/internasional Download kode full klik","title":"Referensi"},{"location":"specimen/","text":"Vector Space Model (VSM). Pada VSM sebuah dokumen akan direpresentasikan dalam sebuah vektor, dimana setiap nilai pada vektor tersebut mewakili bobot term yang bersangkutan. adalah model aljabar yang merepresentasikan kumpulan dokumen sebagai vetctor. VSM dapat diaplikasikan dalam klasifikasi dokumen, clustering dokumen, dan scoring dokumen terhadap sebuah query. Dalam VSM setiap dokumen direpresentasikan sebagai sebuah vector, dimana nilai dari setiap nilai dari vector tersebut mewakili weight sebuah term. Dalam menghitung term-weight dapa digunakan beberapa teknik seperti frequency, binary-document vector, atau tf-idf. Dengan menggunakan Metode Bag of Words Bag of Words merupakan salah satu metode untuk membuat sebuah Vector Space Model (VSM) dengan cara menghitung setiap kata pada setiap dokumen. Contohnya seperti ini Contoh: Artikel 1:anak itu pergi kesekolah Artikel2:anak dan ibu pergi Kita akan menghitung setiap kata tersebut. Maka didapat VSM sebagai berikut: Anak itu pergi kesekolah dan ibu artikel1 1 1 1 1 0 0 artikel2 1 0 1 0 1 1 Untuk kodenya: def countWord(txt, ngram=1): d = dict() token = tokenisasi(txt, ngram) for i in token: if d.get(i) == None: d[i] = txt.count(i) return d Fungsi diatas digunakan untuk menghitung setiap kata pada satu string def add_row_VSM(d): VSM.append([]) for i in VSM[0]: if d.get(i) == None: VSM[-1].append(0) else : VSM[-1].append(d.pop(i)); for i in d: VSM[0].append(i) for j in range(1, len(VSM)-1): #VSM[j].insert(-2,0) VSM[j].append(0) VSM[-1].append(d.get(i)) Fungsi diatas adalah untuk membangun VSM ,jadi kita hanya memasukkan datanya saja , Method counWord digunakan untuk menghitung banyaknya kata pada dokumen. Sementara method add_row_VSM digunakan untuk membuat sebuah matrix VSM tersebut. Untuk pemakaian fungsi diatas adalah seperti dibawah ini. cursor = conn.execute(\"SELECT * from jurnal2\") cursor = cursor.fetchall() cursor = cursor[:60] pertama = True corpus = list() label = list() c=1 n = int(input(\"ngram : \")) #n=1 for row in cursor: print ('Proses : %.2f' %((c/len(cursor))*100) + '%'); c+=1 label.append(row[-1]) txt = row[-2] cleaned = preprosesing(txt) cleaned = cleaned[:-1] corpus.append(cleaned) d = countWord(cleaned, n) if pertama: pertama = False VSM = list((list(), list())) for key in d: VSM[0].append(key) VSM[1].append(d[key]) else: add_row_VSM(d) Lalu untuk menampilkan hasilnya (agar terlihat rapi) maka kita export ke csv. Serta kita pisahkan antara kata-kata dengan nilainya: write_csv(\"bow_manual_%d.csv\"%n, VSM) feature_name = VSM[0] bow = np.array(VSM[1:]) Setelah langkah diatas selanjutnya kita akan melakukan TF-IDF .","title":"Vector Space Model (VSM)"},{"location":"specimen/#vector-space-model-vsm","text":"Pada VSM sebuah dokumen akan direpresentasikan dalam sebuah vektor, dimana setiap nilai pada vektor tersebut mewakili bobot term yang bersangkutan. adalah model aljabar yang merepresentasikan kumpulan dokumen sebagai vetctor. VSM dapat diaplikasikan dalam klasifikasi dokumen, clustering dokumen, dan scoring dokumen terhadap sebuah query. Dalam VSM setiap dokumen direpresentasikan sebagai sebuah vector, dimana nilai dari setiap nilai dari vector tersebut mewakili weight sebuah term. Dalam menghitung term-weight dapa digunakan beberapa teknik seperti frequency, binary-document vector, atau tf-idf. Dengan menggunakan Metode Bag of Words Bag of Words merupakan salah satu metode untuk membuat sebuah Vector Space Model (VSM) dengan cara menghitung setiap kata pada setiap dokumen. Contohnya seperti ini Contoh: Artikel 1:anak itu pergi kesekolah Artikel2:anak dan ibu pergi Kita akan menghitung setiap kata tersebut. Maka didapat VSM sebagai berikut: Anak itu pergi kesekolah dan ibu artikel1 1 1 1 1 0 0 artikel2 1 0 1 0 1 1 Untuk kodenya: def countWord(txt, ngram=1): d = dict() token = tokenisasi(txt, ngram) for i in token: if d.get(i) == None: d[i] = txt.count(i) return d Fungsi diatas digunakan untuk menghitung setiap kata pada satu string def add_row_VSM(d): VSM.append([]) for i in VSM[0]: if d.get(i) == None: VSM[-1].append(0) else : VSM[-1].append(d.pop(i)); for i in d: VSM[0].append(i) for j in range(1, len(VSM)-1): #VSM[j].insert(-2,0) VSM[j].append(0) VSM[-1].append(d.get(i)) Fungsi diatas adalah untuk membangun VSM ,jadi kita hanya memasukkan datanya saja , Method counWord digunakan untuk menghitung banyaknya kata pada dokumen. Sementara method add_row_VSM digunakan untuk membuat sebuah matrix VSM tersebut. Untuk pemakaian fungsi diatas adalah seperti dibawah ini. cursor = conn.execute(\"SELECT * from jurnal2\") cursor = cursor.fetchall() cursor = cursor[:60] pertama = True corpus = list() label = list() c=1 n = int(input(\"ngram : \")) #n=1 for row in cursor: print ('Proses : %.2f' %((c/len(cursor))*100) + '%'); c+=1 label.append(row[-1]) txt = row[-2] cleaned = preprosesing(txt) cleaned = cleaned[:-1] corpus.append(cleaned) d = countWord(cleaned, n) if pertama: pertama = False VSM = list((list(), list())) for key in d: VSM[0].append(key) VSM[1].append(d[key]) else: add_row_VSM(d) Lalu untuk menampilkan hasilnya (agar terlihat rapi) maka kita export ke csv. Serta kita pisahkan antara kata-kata dengan nilainya: write_csv(\"bow_manual_%d.csv\"%n, VSM) feature_name = VSM[0] bow = np.array(VSM[1:]) Setelah langkah diatas selanjutnya kita akan melakukan TF-IDF .","title":"Vector Space Model (VSM)."},{"location":"extensions/admonition/","text":"Admonition Admonition is an extension included in the standard Markdown library that makes it possible to add block-styled side content to your documentation, for example summaries, notes, hints or warnings. Installation Add the following lines to your mkdocs.yml : markdown_extensions: - admonition Usage Admonition blocks follow a simple syntax: every block is started with !!! , followed by a single keyword which is used as the type qualifier of the block. The content of the block then follows on the next line, indented by four spaces. Example: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Changing the title By default, the block title will equal the type qualifier in titlecase. However, it can easily be changed by adding a quoted string after the type qualifier. Example: !!! note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Removing the title Similar to setting a custom title , the icon and title can be omitted by providing an empty string after the type qualifier: Example: !!! note \"\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note \"\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Embedded code blocks Blocks can contain all kinds of text content, including headlines, lists, paragraphs and other blocks \u2013 except code blocks, because the parser from the standard Markdown library does not account for those. However, the PyMdown Extensions package adds an extension called SuperFences , which makes it possible to nest code blocks within other blocks, respectively Admonition blocks. Example: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. ``` mysql SELECT Employees.EmployeeID, Employees.Name, Employees.Salary, Manager.Name AS Manager FROM Employees LEFT JOIN Employees AS Manager ON Employees.ManagerID = Manager.EmployeeID WHERE Employees.EmployeeID = '087652'; ``` Nunc eu odio eleifend, blandit leo a, volutpat sapien. Phasellus posuere in sem ut cursus. Nullam sit amet tincidunt ipsum, sit amet elementum turpis. Etiam ipsum quam, mattis in purus vitae, lacinia fermentum enim. Collapsible blocks The Details extension which is also part of the PyMdown Extensions package adds support for rendering collapsible Admonition blocks. This is useful for FAQs or content that is of secondary nature. Example: ??? note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: ??? note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. By adding a + sign directly after the start marker, blocks can be rendered open by default. Types Admonition supports user-defined type qualifiers which may influence the style of the inserted block. Following is a list of type qualifiers provided by the Material theme, whereas the default type, and thus fallback for unknown type qualifiers, is note . Note Example: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: note seealso Abstract Example: !!! abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: abstract summary tldr Info Example: !!! info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: info todo Tip Example: !!! tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: tip hint important Success Example: !!! success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: success check done Question Example: !!! question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: question help faq Warning Example: !!! warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: warning caution attention Failure Example: !!! failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: failure fail missing Danger Example: !!! danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: danger error Bug Example: !!! bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: bug Example Example: !!! example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: example snippet Quote Example: !!! quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: quote cite","title":"Admonition"},{"location":"extensions/admonition/#admonition","text":"Admonition is an extension included in the standard Markdown library that makes it possible to add block-styled side content to your documentation, for example summaries, notes, hints or warnings.","title":"Admonition"},{"location":"extensions/admonition/#installation","text":"Add the following lines to your mkdocs.yml : markdown_extensions: - admonition","title":"Installation"},{"location":"extensions/admonition/#usage","text":"Admonition blocks follow a simple syntax: every block is started with !!! , followed by a single keyword which is used as the type qualifier of the block. The content of the block then follows on the next line, indented by four spaces. Example: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Usage"},{"location":"extensions/admonition/#changing-the-title","text":"By default, the block title will equal the type qualifier in titlecase. However, it can easily be changed by adding a quoted string after the type qualifier. Example: !!! note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Changing the title"},{"location":"extensions/admonition/#removing-the-title","text":"Similar to setting a custom title , the icon and title can be omitted by providing an empty string after the type qualifier: Example: !!! note \"\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note \"\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Removing the title"},{"location":"extensions/admonition/#embedded-code-blocks","text":"Blocks can contain all kinds of text content, including headlines, lists, paragraphs and other blocks \u2013 except code blocks, because the parser from the standard Markdown library does not account for those. However, the PyMdown Extensions package adds an extension called SuperFences , which makes it possible to nest code blocks within other blocks, respectively Admonition blocks. Example: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. ``` mysql SELECT Employees.EmployeeID, Employees.Name, Employees.Salary, Manager.Name AS Manager FROM Employees LEFT JOIN Employees AS Manager ON Employees.ManagerID = Manager.EmployeeID WHERE Employees.EmployeeID = '087652'; ``` Nunc eu odio eleifend, blandit leo a, volutpat sapien. Phasellus posuere in sem ut cursus. Nullam sit amet tincidunt ipsum, sit amet elementum turpis. Etiam ipsum quam, mattis in purus vitae, lacinia fermentum enim.","title":"Embedded code blocks"},{"location":"extensions/admonition/#collapsible-blocks","text":"The Details extension which is also part of the PyMdown Extensions package adds support for rendering collapsible Admonition blocks. This is useful for FAQs or content that is of secondary nature. Example: ??? note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: ??? note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. By adding a + sign directly after the start marker, blocks can be rendered open by default.","title":"Collapsible blocks"},{"location":"extensions/admonition/#types","text":"Admonition supports user-defined type qualifiers which may influence the style of the inserted block. Following is a list of type qualifiers provided by the Material theme, whereas the default type, and thus fallback for unknown type qualifiers, is note .","title":"Types"},{"location":"extensions/admonition/#note","text":"Example: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: note seealso","title":"Note"},{"location":"extensions/admonition/#abstract","text":"Example: !!! abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: abstract summary tldr","title":"Abstract"},{"location":"extensions/admonition/#info","text":"Example: !!! info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: info todo","title":"Info"},{"location":"extensions/admonition/#tip","text":"Example: !!! tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: tip hint important","title":"Tip"},{"location":"extensions/admonition/#success","text":"Example: !!! success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: success check done","title":"Success"},{"location":"extensions/admonition/#question","text":"Example: !!! question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: question help faq","title":"Question"},{"location":"extensions/admonition/#warning","text":"Example: !!! warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: warning caution attention","title":"Warning"},{"location":"extensions/admonition/#failure","text":"Example: !!! failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: failure fail missing","title":"Failure"},{"location":"extensions/admonition/#danger","text":"Example: !!! danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: danger error","title":"Danger"},{"location":"extensions/admonition/#bug","text":"Example: !!! bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: bug","title":"Bug"},{"location":"extensions/admonition/#example","text":"Example: !!! example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: example snippet","title":"Example"},{"location":"extensions/admonition/#quote","text":"Example: !!! quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: quote cite","title":"Quote"},{"location":"extensions/codehilite/","text":"CodeHilite CodeHilite is an extension that adds syntax highlighting to code blocks and is included in the standard Markdown library. The highlighting process is executed during compilation of the Markdown file. !!! failure \"Syntax highlighting not working?\" Please ensure that [Pygments][2] is installed. See the next section for further directions on how to set up Pygments or use the official [Docker image][3] with all dependencies pre-installed. Installation CodeHilite parses code blocks and wraps them in pre tags. If Pygments is installed, which is a generic syntax highlighter with support for over 300 languages , CodeHilite will also highlight the code block. Pygments can be installed with the following command: pip install pygments To enable CodeHilite, add the following lines to your mkdocs.yml : markdown_extensions: - codehilite Usage Specifying the language The CodeHilite extension uses the same syntax as regular Markdown code blocks, but needs to know the language of the code block. This can be done in three different ways. via Markdown syntax recommended In Markdown, code blocks can be opened and closed by writing three backticks on separate lines. To add code highlighting to those blocks, the easiest way is to specify the language directly after the opening block. Example: ``` python import tensorflow as tf ``` Result: import tensorflow as tf via Shebang Alternatively, if the first line of a code block contains a shebang, the language is derived from the path referenced in the shebang. This will only work for code blocks that are indented using four spaces, not for those encapsulated in three backticks. Example: #!/usr/bin/python import tensorflow as tf Result: #!/usr/bin/python import tensorflow as tf via three colons If the first line starts with three colons followed by a language identifier, the first line is stripped. This will only work for code blocks that are indented using four spaces, not for those encapsulated in three backticks. Example: :::python import tensorflow as tf Result: :::python import tensorflow as tf Adding line numbers Line numbers can be added by enabling the linenums flag in your mkdocs.yml : markdown_extensions: - codehilite: linenums: true Example: ``` python \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` Result: #!python \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] Grouping code blocks The SuperFences extension which is part of the PyMdown Extensions package adds support for grouping code blocks with tabs. This is especially useful for documenting projects with multiple language bindings. Example: ``` bash tab=\"Bash\" #!/bin/bash echo \"Hello world!\" ``` ``` c tab=\"C\" #include <stdio.h> int main(void) { printf(\"Hello world!\\n\"); } ``` ``` c++ tab=\"C++\" #include <iostream> int main() { std::cout << \"Hello world!\" << std::endl; return 0; } ``` ``` c# tab=\"C#\" using System; class Program { static void Main(string[] args) { Console.WriteLine(\"Hello world!\"); } } ``` Result: ``` bash tab=\"Bash\" !/bin/bash echo \"Hello world!\" ``` c tab=\"C\" #include <stdio.h> int main(void) { printf(\"Hello world!\\n\"); } ``` c++ tab=\"C++\" include int main() { std::cout << \"Hello world!\" << std::endl; return 0; } ``` c# tab=\"C#\" using System; class Program { static void Main(string[] args) { Console.WriteLine(\"Hello world!\"); } } Highlighting specific lines Specific lines can be highlighted by passing the line numbers to the hl_lines argument placed right after the language identifier. Line counts start at 1. Example: ``` python hl_lines=\"3 4\" \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` Result: #!python hl_lines=\"3 4\" \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] Supported languages excerpt CodeHilite uses Pygments , a generic syntax highlighter with support for over 300 languages , so the following list of examples is just an excerpt. Bash #!/bin/bash for OPT in \"$@\" do case \"$OPT\" in '-f' ) canonicalize=1 ;; '-n' ) switchlf=\"-n\" ;; esac done # readlink -f function __readlink_f { target=\"$1\" while test -n \"$target\"; do filepath=\"$target\" cd `dirname \"$filepath\"` target=`readlink \"$filepath\"` done /bin/echo $switchlf `pwd -P`/`basename \"$filepath\"` } if [ ! \"$canonicalize\" ]; then readlink $switchlf \"$@\" else for file in \"$@\" do case \"$file\" in -* ) ;; * ) __readlink_f \"$file\" ;; esac done fi exit $? C extern size_t pb_varint_scan(const uint8_t data[], size_t left) { assert(data && left); left = left > 10 ? 10 : left; #ifdef __SSE2__ /* Mapping: remaining bytes ==> bitmask */ static const int mask_map[] = { 0x0000, 0x0001, 0x0003, 0x0007, 0x000F, 0x001F, 0x003F, 0x007F, 0x00FF, 0x01FF, 0x03FF }; /* Load buffer into 128-bit integer and create high-bit mask */ __m128i temp = _mm_loadu_si128((const __m128i *)data); __m128i high = _mm_set1_epi8(0x80); /* Intersect and extract mask with high-bits set */ int mask = _mm_movemask_epi8(_mm_and_si128(temp, high)); mask = (mask & mask_map[left]) ^ mask_map[left]; /* Count trailing zeroes */ return mask ? __builtin_ctz(mask) + 1 : 0; #else /* Linear scan */ size_t size = 0; while (data[size++] & 0x80) if (!--left) return 0; return size; #endif /* __SSE2__ */ } C++ Extension:: Extension(const Descriptor *descriptor, const Descriptor *scope) : descriptor_(descriptor), scope_(scope) { /* Extract full name for signature */ variables_[\"signature\"] = descriptor_->full_name(); /* Prepare message symbol */ variables_[\"message\"] = StringReplace( variables_[\"signature\"], \".\", \"_\", true); LowerString(&(variables_[\"message\"])); /* Suffix scope to identifiers, if given */ string suffix (\"\"); if (scope_) { suffix = scope_->full_name(); /* Check if the base and extension types are in the same package */ if (!scope_->file()->package().compare(descriptor_->file()->package())) suffix = StripPrefixString(suffix, scope_->file()->package() + \".\"); /* Append to signature */ variables_[\"signature\"] += \".[\" + suffix +\"]\"; suffix = \"_\" + suffix; } /* Prepare extension symbol */ variables_[\"extension\"] = StringReplace( suffix, \".\", \"_\", true); LowerString(&(variables_[\"extension\"])); } C# public static void Send( Socket socket, byte[] buffer, int offset, int size, int timeout) { int startTickCount = Environment.TickCount; int sent = 0; do { if (Environment.TickCount > startTickCount + timeout) throw new Exception(\"Timeout.\"); try { sent += socket.Send(buffer, offset + sent, size - sent, SocketFlags.None); } catch (SocketException ex) { if (ex.SocketErrorCode == SocketError.WouldBlock || ex.SocketErrorCode == SocketError.IOPending || ex.SocketErrorCode == SocketError.NoBufferSpaceAvailable) { /* Socket buffer is probably full, wait and try again */ Thread.Sleep(30); } else { throw ex; } } } while (sent < size); } Clojure (clojure-version) (defn partition-when [f] (fn [rf] (let [a (java.util.ArrayList.) fval (volatile! false)] (fn ([] (rf)) ([result] (let [result (if (.isEmpty a) result (let [v (vec (.toArray a))] ;; Clear first (.clear a) (unreduced (rf result v))))] (rf result))) ([result input] (if-not (and (f input) @fval) (do (vreset! fval true) (.add a input) result) (let [v (vec (.toArray a))] (.clear a) (let [ret (rf result v)] (when-not (reduced? ret) (.add a input)) ret)))))))) (into [] (partition-when #(.startsWith % \">>\")) [\"1d\" \"33\" \">> 1\" \">> 2\" \"22\" \">> 3\"]) Diff Index: grunt.js =================================================================== --- grunt.js (revision 31200) +++ grunt.js (working copy) @@ -12,6 +12,7 @@ module.exports = function (grunt) { + console.log('hello world'); // Project configuration. grunt.initConfig({ lint: { @@ -19,10 +20,6 @@ 'packages/services.web/{!(test)/**/,}*.js', 'packages/error/**/*.js' ], - scripts: [ - 'grunt.js', - 'db/**/*.js' - ], browser: [ 'packages/web/server.js', 'packages/web/server/**/*.js', Docker FROM ubuntu # Install vnc, xvfb in order to create a 'fake' display and firefox RUN apt-get update && apt-get install -y x11vnc xvfb firefox RUN mkdir ~/.vnc # Setup a password RUN x11vnc -storepasswd 1234 ~/.vnc/passwd # Autostart firefox (might not be the best way, but it does the trick) RUN bash -c 'echo \"firefox\" >> /.bashrc' EXPOSE 5900 CMD [\"x11vnc\", \"-forever\", \"-usepw\", \"-create\"] Elixir require Logger def accept(port) do {:ok, socket} = :gen_tcp.listen(port, [:binary, packet: :line, active: false, reuseaddr: true]) Logger.info \"Accepting connections on port #{port}\" loop_acceptor(socket) end defp loop_acceptor(socket) do {:ok, client} = :gen_tcp.accept(socket) serve(client) loop_acceptor(socket) end defp serve(socket) do socket |> read_line() |> write_line(socket) serve(socket) end defp read_line(socket) do {:ok, data} = :gen_tcp.recv(socket, 0) data end defp write_line(line, socket) do :gen_tcp.send(socket, line) end Erlang circular(Defs) -> [ { { Type, Base }, Fields } || { { Type, Base }, Fields } <- Defs, Type == msg, circular(Base, Defs) ]. circular(Base, Defs) -> Fields = proplists:get_value({ msg, Base }, Defs), circular(Defs, Fields, [Base]). circular(_Defs, [], _Path) -> false; circular(Defs, [Field | Fields], Path) -> case Field#field.type of { msg, Type } -> case lists:member(Type, Path) of false -> Children = proplists:get_value({ msg, Type }, Defs), case circular(Defs, Children, [Type | Path]) of false -> circular(Defs, Fields, Path); true -> true end; true -> Type == lists:last(Path) andalso (length(Path) == 1 orelse not is_tree(Path)) end; _ -> circular(Defs, Fields, Path) end. F# /// Asynchronously download retangles from the server /// and decode the JSON format to F# Rectangle record let [<Js>] getRectangles () : Async<Rectangle[]> = async { let req = XMLHttpRequest() req.Open(\"POST\", \"/get\", true) let! resp = req.AsyncSend() return JSON.parse(resp) } /// Repeatedly update rectangles after 0.5 sec let [<Js>] updateLoop () = async { while true do do! Async.Sleep(500) let! rects = getRectangles() cleanRectangles() rects |> Array.iter createRectangle } Go package main import \"fmt\" func counter(id int, channel chan int, closer bool) { for i := 0; i < 10000000; i++ { fmt.Println(\"process\", id,\" send\", i) channel <- 1 } if closer { close(channel ) } } func main() { channel := make(chan int) go counter(1, channel, false) go counter(2, channel, true) x := 0 // receiving data from channel for i := range channel { fmt.Println(\"receiving\") x += i } fmt.Println(x) } HTML <!doctype html> <html class=\"no-js\" lang=\"\"> <head> <meta charset=\"utf-8\"> <meta http-equiv=\"x-ua-compatible\" content=\"ie=edge\"> <title>HTML5 Boilerplate</title> <meta name=\"description\" content=\"\"> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"> <link rel=\"apple-touch-icon\" href=\"apple-touch-icon.png\"> <link rel=\"stylesheet\" href=\"css/normalize.css\"> <link rel=\"stylesheet\" href=\"css/main.css\"> <script src=\"js/vendor/modernizr-2.8.3.min.js\"></script> </head> <body> <p>Hello world! This is HTML5 Boilerplate.</p> </body> </html> Java import java.util.LinkedList; import java.lang.reflect.Array; public class UnsortedHashSet<E> { private static final double LOAD_FACTOR_LIMIT = 0.7; private int size; private LinkedList<E>[] con; public UnsortedHashSet() { con = (LinkedList<E>[])(new LinkedList[10]); } public boolean add(E obj) { int oldSize = size; int index = Math.abs(obj.hashCode()) % con.length; if (con[index] == null) con[index] = new LinkedList<E>(); if (!con[index].contains(obj)) { con[index].add(obj); size++; } if (1.0 * size / con.length > LOAD_FACTOR_LIMIT) resize(); return oldSize != size; } private void resize() { UnsortedHashSet<E> temp = new UnsortedHashSet<E>(); temp.con = (LinkedList<E>[])(new LinkedList[con.length * 2 + 1]); for (int i = 0; i < con.length; i++) { if (con[i] != null) for (E e : con[i]) temp.add(e); } con = temp.con; } public int size() { return size; } } JavaScript var Math = require('lib/math'); var _extends = function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { target[key] = source[key]; } } return target; }; var e = exports.e = 2.71828182846; exports['default'] = function (x) { return Math.exp(x); }; module.exports = _extends(exports['default'], exports); JSON { \"name\": \"mkdocs-material\", \"version\": \"0.2.4\", \"description\": \"A Material Design theme for MkDocs\", \"homepage\": \"http://squidfunk.github.io/mkdocs-material/\", \"authors\": [ \"squidfunk <martin.donath@squidfunk.com>\" ], \"license\": \"MIT\", \"main\": \"Gulpfile.js\", \"scripts\": { \"start\": \"./node_modules/.bin/gulp watch --mkdocs\", \"build\": \"./node_modules/.bin/gulp build --production\" } ... } Julia using MXNet mlp = @mx.chain mx.Variable(:data) => mx.FullyConnected(name=:fc1, num_hidden=128) => mx.Activation(name=:relu1, act_type=:relu) => mx.FullyConnected(name=:fc2, num_hidden=64) => mx.Activation(name=:relu2, act_type=:relu) => mx.FullyConnected(name=:fc3, num_hidden=10) => mx.SoftmaxOutput(name=:softmax) # data provider batch_size = 100 include(Pkg.dir(\"MXNet\", \"examples\", \"mnist\", \"mnist-data.jl\")) train_provider, eval_provider = get_mnist_providers(batch_size) # setup model model = mx.FeedForward(mlp, context=mx.cpu()) # optimization algorithm optimizer = mx.SGD(lr=0.1, momentum=0.9) # fit parameters mx.fit(model, optimizer, train_provider, n_epoch=20, eval_data=eval_provider) Lua local ffi = require(\"ffi\") ffi.cdef[[ void Sleep(int ms); int poll(struct pollfd *fds, unsigned long nfds, int timeout); ]] local sleep if ffi.os == \"Windows\" then function sleep(s) ffi.C.Sleep(s*1000) end else function sleep(s) ffi.C.poll(nil, 0, s * 1000) end end for i = 1,160 do io.write(\".\"); io.flush() sleep(0.01) end io.write(\"\\n\") MySQL SELECT Employees.EmployeeID, Employees.Name, Employees.Salary, Manager.Name AS Manager FROM Employees LEFT JOIN Employees AS Manager ON Employees.ManagerID = Manager.EmployeeID WHERE Employees.EmployeeID = '087652'; PHP <?php // src/AppBundle/Controller/LuckyController.php namespace AppBundle\\Controller; use Sensio\\Bundle\\FrameworkExtraBundle\\Configuration\\Route; use Symfony\\Component\\HttpFoundation\\Response; class LuckyController { /** * @Route(\"/lucky/number\") */ public function numberAction() { $number = mt_rand(0, 100); return new Response( '<html><body>Lucky number: '.$number.'</body></html>' ); } } Protocol Buffers syntax = \"proto2\"; package caffe; // Specifies the shape (dimensions) of a Blob. message BlobShape { repeated int64 dim = 1 [packed = true]; } message BlobProto { optional BlobShape shape = 7; repeated float data = 5 [packed = true]; repeated float diff = 6 [packed = true]; // 4D dimensions -- deprecated. Use \"shape\" instead. optional int32 num = 1 [default = 0]; optional int32 channels = 2 [default = 0]; optional int32 height = 3 [default = 0]; optional int32 width = 4 [default = 0]; } Python \"\"\" A very simple MNIST classifier. See extensive documentation at http://tensorflow.org/tutorials/mnist/beginners/index.md \"\"\" from __future__ import absolute_import from __future__ import division from __future__ import print_function # Import data from tensorflow.examples.tutorials.mnist import input_data import tensorflow as tf flags = tf.app.flags FLAGS = flags.FLAGS flags.DEFINE_string('data_dir', '/tmp/data/', 'Directory for storing data') mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True) sess = tf.InteractiveSession() # Create the model x = tf.placeholder(tf.float32, [None, 784]) W = tf.Variable(tf.zeros([784, 10])) b = tf.Variable(tf.zeros([10])) y = tf.nn.softmax(tf.matmul(x, W) + b) Ruby require 'finity/event' require 'finity/machine' require 'finity/state' require 'finity/transition' require 'finity/version' module Finity class InvalidCallback < StandardError; end class MissingCallback < StandardError; end class InvalidState < StandardError; end # Class methods to be injected into the including class upon inclusion. module ClassMethods # Instantiate a new state machine for the including class by accepting a # block with state and event (and subsequent transition) definitions. def finity options = {}, &block @finity ||= Machine.new self, options, &block end # Return the names of all registered states. def states @finity.states.map { |name, _| name } end # Return the names of all registered events. def events @finity.events.map { |name, _| name } end end # Inject methods into the including class upon inclusion. def self.included base base.extend ClassMethods end end XML <?xml version=\"1.0\" encoding=\"UTF-8\"?> <!DOCTYPE mainTag SYSTEM \"some.dtd\" [ENTITY % entity]> <?oxygen RNGSchema=\"some.rng\" type=\"xml\"?> <xs:main-Tag xmlns:xs=\"http://www.w3.org/2001/XMLSchema\"> <!-- This is a sample comment --> <childTag attribute=\"Quoted Value\" another-attribute='Single quoted value' a-third-attribute='123'> <withTextContent>Some text content</withTextContent> <withEntityContent>Some text content with &lt;entities&gt; and mentioning uint8_t and int32_t</withEntityContent> <otherTag attribute='Single quoted Value'/> </childTag> <![CDATA[ some CData ]]> </main-Tag>","title":"CodeHilite"},{"location":"extensions/codehilite/#codehilite","text":"CodeHilite is an extension that adds syntax highlighting to code blocks and is included in the standard Markdown library. The highlighting process is executed during compilation of the Markdown file. !!! failure \"Syntax highlighting not working?\" Please ensure that [Pygments][2] is installed. See the next section for further directions on how to set up Pygments or use the official [Docker image][3] with all dependencies pre-installed.","title":"CodeHilite"},{"location":"extensions/codehilite/#installation","text":"CodeHilite parses code blocks and wraps them in pre tags. If Pygments is installed, which is a generic syntax highlighter with support for over 300 languages , CodeHilite will also highlight the code block. Pygments can be installed with the following command: pip install pygments To enable CodeHilite, add the following lines to your mkdocs.yml : markdown_extensions: - codehilite","title":"Installation"},{"location":"extensions/codehilite/#usage","text":"","title":"Usage"},{"location":"extensions/codehilite/#specifying-the-language","text":"The CodeHilite extension uses the same syntax as regular Markdown code blocks, but needs to know the language of the code block. This can be done in three different ways.","title":"Specifying the language"},{"location":"extensions/codehilite/#via-markdown-syntax-recommended","text":"In Markdown, code blocks can be opened and closed by writing three backticks on separate lines. To add code highlighting to those blocks, the easiest way is to specify the language directly after the opening block. Example: ``` python import tensorflow as tf ``` Result: import tensorflow as tf","title":"via Markdown syntax recommended"},{"location":"extensions/codehilite/#via-shebang","text":"Alternatively, if the first line of a code block contains a shebang, the language is derived from the path referenced in the shebang. This will only work for code blocks that are indented using four spaces, not for those encapsulated in three backticks. Example: #!/usr/bin/python import tensorflow as tf Result: #!/usr/bin/python import tensorflow as tf","title":"via Shebang"},{"location":"extensions/codehilite/#via-three-colons","text":"If the first line starts with three colons followed by a language identifier, the first line is stripped. This will only work for code blocks that are indented using four spaces, not for those encapsulated in three backticks. Example: :::python import tensorflow as tf Result: :::python import tensorflow as tf","title":"via three colons"},{"location":"extensions/codehilite/#adding-line-numbers","text":"Line numbers can be added by enabling the linenums flag in your mkdocs.yml : markdown_extensions: - codehilite: linenums: true Example: ``` python \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` Result: #!python \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j]","title":"Adding line numbers"},{"location":"extensions/codehilite/#grouping-code-blocks","text":"The SuperFences extension which is part of the PyMdown Extensions package adds support for grouping code blocks with tabs. This is especially useful for documenting projects with multiple language bindings. Example: ``` bash tab=\"Bash\" #!/bin/bash echo \"Hello world!\" ``` ``` c tab=\"C\" #include <stdio.h> int main(void) { printf(\"Hello world!\\n\"); } ``` ``` c++ tab=\"C++\" #include <iostream> int main() { std::cout << \"Hello world!\" << std::endl; return 0; } ``` ``` c# tab=\"C#\" using System; class Program { static void Main(string[] args) { Console.WriteLine(\"Hello world!\"); } } ``` Result: ``` bash tab=\"Bash\"","title":"Grouping code blocks"},{"location":"extensions/codehilite/#binbash","text":"echo \"Hello world!\" ``` c tab=\"C\" #include <stdio.h> int main(void) { printf(\"Hello world!\\n\"); } ``` c++ tab=\"C++\"","title":"!/bin/bash"},{"location":"extensions/codehilite/#include","text":"int main() { std::cout << \"Hello world!\" << std::endl; return 0; } ``` c# tab=\"C#\" using System; class Program { static void Main(string[] args) { Console.WriteLine(\"Hello world!\"); } }","title":"include "},{"location":"extensions/codehilite/#highlighting-specific-lines","text":"Specific lines can be highlighted by passing the line numbers to the hl_lines argument placed right after the language identifier. Line counts start at 1. Example: ``` python hl_lines=\"3 4\" \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` Result: #!python hl_lines=\"3 4\" \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j]","title":"Highlighting specific lines"},{"location":"extensions/codehilite/#supported-languages-excerpt","text":"CodeHilite uses Pygments , a generic syntax highlighter with support for over 300 languages , so the following list of examples is just an excerpt.","title":"Supported languages excerpt"},{"location":"extensions/codehilite/#bash","text":"#!/bin/bash for OPT in \"$@\" do case \"$OPT\" in '-f' ) canonicalize=1 ;; '-n' ) switchlf=\"-n\" ;; esac done # readlink -f function __readlink_f { target=\"$1\" while test -n \"$target\"; do filepath=\"$target\" cd `dirname \"$filepath\"` target=`readlink \"$filepath\"` done /bin/echo $switchlf `pwd -P`/`basename \"$filepath\"` } if [ ! \"$canonicalize\" ]; then readlink $switchlf \"$@\" else for file in \"$@\" do case \"$file\" in -* ) ;; * ) __readlink_f \"$file\" ;; esac done fi exit $?","title":"Bash"},{"location":"extensions/codehilite/#c","text":"extern size_t pb_varint_scan(const uint8_t data[], size_t left) { assert(data && left); left = left > 10 ? 10 : left; #ifdef __SSE2__ /* Mapping: remaining bytes ==> bitmask */ static const int mask_map[] = { 0x0000, 0x0001, 0x0003, 0x0007, 0x000F, 0x001F, 0x003F, 0x007F, 0x00FF, 0x01FF, 0x03FF }; /* Load buffer into 128-bit integer and create high-bit mask */ __m128i temp = _mm_loadu_si128((const __m128i *)data); __m128i high = _mm_set1_epi8(0x80); /* Intersect and extract mask with high-bits set */ int mask = _mm_movemask_epi8(_mm_and_si128(temp, high)); mask = (mask & mask_map[left]) ^ mask_map[left]; /* Count trailing zeroes */ return mask ? __builtin_ctz(mask) + 1 : 0; #else /* Linear scan */ size_t size = 0; while (data[size++] & 0x80) if (!--left) return 0; return size; #endif /* __SSE2__ */ }","title":"C"},{"location":"extensions/codehilite/#c_1","text":"Extension:: Extension(const Descriptor *descriptor, const Descriptor *scope) : descriptor_(descriptor), scope_(scope) { /* Extract full name for signature */ variables_[\"signature\"] = descriptor_->full_name(); /* Prepare message symbol */ variables_[\"message\"] = StringReplace( variables_[\"signature\"], \".\", \"_\", true); LowerString(&(variables_[\"message\"])); /* Suffix scope to identifiers, if given */ string suffix (\"\"); if (scope_) { suffix = scope_->full_name(); /* Check if the base and extension types are in the same package */ if (!scope_->file()->package().compare(descriptor_->file()->package())) suffix = StripPrefixString(suffix, scope_->file()->package() + \".\"); /* Append to signature */ variables_[\"signature\"] += \".[\" + suffix +\"]\"; suffix = \"_\" + suffix; } /* Prepare extension symbol */ variables_[\"extension\"] = StringReplace( suffix, \".\", \"_\", true); LowerString(&(variables_[\"extension\"])); }","title":"C++"},{"location":"extensions/codehilite/#c_2","text":"public static void Send( Socket socket, byte[] buffer, int offset, int size, int timeout) { int startTickCount = Environment.TickCount; int sent = 0; do { if (Environment.TickCount > startTickCount + timeout) throw new Exception(\"Timeout.\"); try { sent += socket.Send(buffer, offset + sent, size - sent, SocketFlags.None); } catch (SocketException ex) { if (ex.SocketErrorCode == SocketError.WouldBlock || ex.SocketErrorCode == SocketError.IOPending || ex.SocketErrorCode == SocketError.NoBufferSpaceAvailable) { /* Socket buffer is probably full, wait and try again */ Thread.Sleep(30); } else { throw ex; } } } while (sent < size); }","title":"C&#35;"},{"location":"extensions/codehilite/#clojure","text":"(clojure-version) (defn partition-when [f] (fn [rf] (let [a (java.util.ArrayList.) fval (volatile! false)] (fn ([] (rf)) ([result] (let [result (if (.isEmpty a) result (let [v (vec (.toArray a))] ;; Clear first (.clear a) (unreduced (rf result v))))] (rf result))) ([result input] (if-not (and (f input) @fval) (do (vreset! fval true) (.add a input) result) (let [v (vec (.toArray a))] (.clear a) (let [ret (rf result v)] (when-not (reduced? ret) (.add a input)) ret)))))))) (into [] (partition-when #(.startsWith % \">>\")) [\"1d\" \"33\" \">> 1\" \">> 2\" \"22\" \">> 3\"])","title":"Clojure"},{"location":"extensions/codehilite/#diff","text":"Index: grunt.js =================================================================== --- grunt.js (revision 31200) +++ grunt.js (working copy) @@ -12,6 +12,7 @@ module.exports = function (grunt) { + console.log('hello world'); // Project configuration. grunt.initConfig({ lint: { @@ -19,10 +20,6 @@ 'packages/services.web/{!(test)/**/,}*.js', 'packages/error/**/*.js' ], - scripts: [ - 'grunt.js', - 'db/**/*.js' - ], browser: [ 'packages/web/server.js', 'packages/web/server/**/*.js',","title":"Diff"},{"location":"extensions/codehilite/#docker","text":"FROM ubuntu # Install vnc, xvfb in order to create a 'fake' display and firefox RUN apt-get update && apt-get install -y x11vnc xvfb firefox RUN mkdir ~/.vnc # Setup a password RUN x11vnc -storepasswd 1234 ~/.vnc/passwd # Autostart firefox (might not be the best way, but it does the trick) RUN bash -c 'echo \"firefox\" >> /.bashrc' EXPOSE 5900 CMD [\"x11vnc\", \"-forever\", \"-usepw\", \"-create\"]","title":"Docker"},{"location":"extensions/codehilite/#elixir","text":"require Logger def accept(port) do {:ok, socket} = :gen_tcp.listen(port, [:binary, packet: :line, active: false, reuseaddr: true]) Logger.info \"Accepting connections on port #{port}\" loop_acceptor(socket) end defp loop_acceptor(socket) do {:ok, client} = :gen_tcp.accept(socket) serve(client) loop_acceptor(socket) end defp serve(socket) do socket |> read_line() |> write_line(socket) serve(socket) end defp read_line(socket) do {:ok, data} = :gen_tcp.recv(socket, 0) data end defp write_line(line, socket) do :gen_tcp.send(socket, line) end","title":"Elixir"},{"location":"extensions/codehilite/#erlang","text":"circular(Defs) -> [ { { Type, Base }, Fields } || { { Type, Base }, Fields } <- Defs, Type == msg, circular(Base, Defs) ]. circular(Base, Defs) -> Fields = proplists:get_value({ msg, Base }, Defs), circular(Defs, Fields, [Base]). circular(_Defs, [], _Path) -> false; circular(Defs, [Field | Fields], Path) -> case Field#field.type of { msg, Type } -> case lists:member(Type, Path) of false -> Children = proplists:get_value({ msg, Type }, Defs), case circular(Defs, Children, [Type | Path]) of false -> circular(Defs, Fields, Path); true -> true end; true -> Type == lists:last(Path) andalso (length(Path) == 1 orelse not is_tree(Path)) end; _ -> circular(Defs, Fields, Path) end.","title":"Erlang"},{"location":"extensions/codehilite/#f","text":"/// Asynchronously download retangles from the server /// and decode the JSON format to F# Rectangle record let [<Js>] getRectangles () : Async<Rectangle[]> = async { let req = XMLHttpRequest() req.Open(\"POST\", \"/get\", true) let! resp = req.AsyncSend() return JSON.parse(resp) } /// Repeatedly update rectangles after 0.5 sec let [<Js>] updateLoop () = async { while true do do! Async.Sleep(500) let! rects = getRectangles() cleanRectangles() rects |> Array.iter createRectangle }","title":"F&#35;"},{"location":"extensions/codehilite/#go","text":"package main import \"fmt\" func counter(id int, channel chan int, closer bool) { for i := 0; i < 10000000; i++ { fmt.Println(\"process\", id,\" send\", i) channel <- 1 } if closer { close(channel ) } } func main() { channel := make(chan int) go counter(1, channel, false) go counter(2, channel, true) x := 0 // receiving data from channel for i := range channel { fmt.Println(\"receiving\") x += i } fmt.Println(x) }","title":"Go"},{"location":"extensions/codehilite/#html","text":"<!doctype html> <html class=\"no-js\" lang=\"\"> <head> <meta charset=\"utf-8\"> <meta http-equiv=\"x-ua-compatible\" content=\"ie=edge\"> <title>HTML5 Boilerplate</title> <meta name=\"description\" content=\"\"> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"> <link rel=\"apple-touch-icon\" href=\"apple-touch-icon.png\"> <link rel=\"stylesheet\" href=\"css/normalize.css\"> <link rel=\"stylesheet\" href=\"css/main.css\"> <script src=\"js/vendor/modernizr-2.8.3.min.js\"></script> </head> <body> <p>Hello world! This is HTML5 Boilerplate.</p> </body> </html>","title":"HTML"},{"location":"extensions/codehilite/#java","text":"import java.util.LinkedList; import java.lang.reflect.Array; public class UnsortedHashSet<E> { private static final double LOAD_FACTOR_LIMIT = 0.7; private int size; private LinkedList<E>[] con; public UnsortedHashSet() { con = (LinkedList<E>[])(new LinkedList[10]); } public boolean add(E obj) { int oldSize = size; int index = Math.abs(obj.hashCode()) % con.length; if (con[index] == null) con[index] = new LinkedList<E>(); if (!con[index].contains(obj)) { con[index].add(obj); size++; } if (1.0 * size / con.length > LOAD_FACTOR_LIMIT) resize(); return oldSize != size; } private void resize() { UnsortedHashSet<E> temp = new UnsortedHashSet<E>(); temp.con = (LinkedList<E>[])(new LinkedList[con.length * 2 + 1]); for (int i = 0; i < con.length; i++) { if (con[i] != null) for (E e : con[i]) temp.add(e); } con = temp.con; } public int size() { return size; } }","title":"Java"},{"location":"extensions/codehilite/#javascript","text":"var Math = require('lib/math'); var _extends = function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { target[key] = source[key]; } } return target; }; var e = exports.e = 2.71828182846; exports['default'] = function (x) { return Math.exp(x); }; module.exports = _extends(exports['default'], exports);","title":"JavaScript"},{"location":"extensions/codehilite/#json","text":"{ \"name\": \"mkdocs-material\", \"version\": \"0.2.4\", \"description\": \"A Material Design theme for MkDocs\", \"homepage\": \"http://squidfunk.github.io/mkdocs-material/\", \"authors\": [ \"squidfunk <martin.donath@squidfunk.com>\" ], \"license\": \"MIT\", \"main\": \"Gulpfile.js\", \"scripts\": { \"start\": \"./node_modules/.bin/gulp watch --mkdocs\", \"build\": \"./node_modules/.bin/gulp build --production\" } ... }","title":"JSON"},{"location":"extensions/codehilite/#julia","text":"using MXNet mlp = @mx.chain mx.Variable(:data) => mx.FullyConnected(name=:fc1, num_hidden=128) => mx.Activation(name=:relu1, act_type=:relu) => mx.FullyConnected(name=:fc2, num_hidden=64) => mx.Activation(name=:relu2, act_type=:relu) => mx.FullyConnected(name=:fc3, num_hidden=10) => mx.SoftmaxOutput(name=:softmax) # data provider batch_size = 100 include(Pkg.dir(\"MXNet\", \"examples\", \"mnist\", \"mnist-data.jl\")) train_provider, eval_provider = get_mnist_providers(batch_size) # setup model model = mx.FeedForward(mlp, context=mx.cpu()) # optimization algorithm optimizer = mx.SGD(lr=0.1, momentum=0.9) # fit parameters mx.fit(model, optimizer, train_provider, n_epoch=20, eval_data=eval_provider)","title":"Julia"},{"location":"extensions/codehilite/#lua","text":"local ffi = require(\"ffi\") ffi.cdef[[ void Sleep(int ms); int poll(struct pollfd *fds, unsigned long nfds, int timeout); ]] local sleep if ffi.os == \"Windows\" then function sleep(s) ffi.C.Sleep(s*1000) end else function sleep(s) ffi.C.poll(nil, 0, s * 1000) end end for i = 1,160 do io.write(\".\"); io.flush() sleep(0.01) end io.write(\"\\n\")","title":"Lua"},{"location":"extensions/codehilite/#mysql","text":"SELECT Employees.EmployeeID, Employees.Name, Employees.Salary, Manager.Name AS Manager FROM Employees LEFT JOIN Employees AS Manager ON Employees.ManagerID = Manager.EmployeeID WHERE Employees.EmployeeID = '087652';","title":"MySQL"},{"location":"extensions/codehilite/#php","text":"<?php // src/AppBundle/Controller/LuckyController.php namespace AppBundle\\Controller; use Sensio\\Bundle\\FrameworkExtraBundle\\Configuration\\Route; use Symfony\\Component\\HttpFoundation\\Response; class LuckyController { /** * @Route(\"/lucky/number\") */ public function numberAction() { $number = mt_rand(0, 100); return new Response( '<html><body>Lucky number: '.$number.'</body></html>' ); } }","title":"PHP"},{"location":"extensions/codehilite/#protocol-buffers","text":"syntax = \"proto2\"; package caffe; // Specifies the shape (dimensions) of a Blob. message BlobShape { repeated int64 dim = 1 [packed = true]; } message BlobProto { optional BlobShape shape = 7; repeated float data = 5 [packed = true]; repeated float diff = 6 [packed = true]; // 4D dimensions -- deprecated. Use \"shape\" instead. optional int32 num = 1 [default = 0]; optional int32 channels = 2 [default = 0]; optional int32 height = 3 [default = 0]; optional int32 width = 4 [default = 0]; }","title":"Protocol Buffers"},{"location":"extensions/codehilite/#python","text":"\"\"\" A very simple MNIST classifier. See extensive documentation at http://tensorflow.org/tutorials/mnist/beginners/index.md \"\"\" from __future__ import absolute_import from __future__ import division from __future__ import print_function # Import data from tensorflow.examples.tutorials.mnist import input_data import tensorflow as tf flags = tf.app.flags FLAGS = flags.FLAGS flags.DEFINE_string('data_dir', '/tmp/data/', 'Directory for storing data') mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True) sess = tf.InteractiveSession() # Create the model x = tf.placeholder(tf.float32, [None, 784]) W = tf.Variable(tf.zeros([784, 10])) b = tf.Variable(tf.zeros([10])) y = tf.nn.softmax(tf.matmul(x, W) + b)","title":"Python"},{"location":"extensions/codehilite/#ruby","text":"require 'finity/event' require 'finity/machine' require 'finity/state' require 'finity/transition' require 'finity/version' module Finity class InvalidCallback < StandardError; end class MissingCallback < StandardError; end class InvalidState < StandardError; end # Class methods to be injected into the including class upon inclusion. module ClassMethods # Instantiate a new state machine for the including class by accepting a # block with state and event (and subsequent transition) definitions. def finity options = {}, &block @finity ||= Machine.new self, options, &block end # Return the names of all registered states. def states @finity.states.map { |name, _| name } end # Return the names of all registered events. def events @finity.events.map { |name, _| name } end end # Inject methods into the including class upon inclusion. def self.included base base.extend ClassMethods end end","title":"Ruby"},{"location":"extensions/codehilite/#xml","text":"<?xml version=\"1.0\" encoding=\"UTF-8\"?> <!DOCTYPE mainTag SYSTEM \"some.dtd\" [ENTITY % entity]> <?oxygen RNGSchema=\"some.rng\" type=\"xml\"?> <xs:main-Tag xmlns:xs=\"http://www.w3.org/2001/XMLSchema\"> <!-- This is a sample comment --> <childTag attribute=\"Quoted Value\" another-attribute='Single quoted value' a-third-attribute='123'> <withTextContent>Some text content</withTextContent> <withEntityContent>Some text content with &lt;entities&gt; and mentioning uint8_t and int32_t</withEntityContent> <otherTag attribute='Single quoted Value'/> </childTag> <![CDATA[ some CData ]]> </main-Tag>","title":"XML"},{"location":"extensions/footnotes/","text":"Footnotes Footnotes is another extension included in the standard Markdown library. As the name says, it adds the ability to add footnotes to your documentation. Installation Add the following lines to your mkdocs.yml : markdown_extensions: - footnotes Usage The markup for footnotes is similar to the standard Markdown markup for links. A reference is inserted in the text, which can then be defined at any point in the document. Inserting the reference The footnote reference is enclosed in square brackets and starts with a caret, followed by an arbitrary label which may contain numeric identifiers [1, 2, 3, ...] or names [Granovetter et al. 1998]. The rendered references are always consecutive superscripted numbers. Example: Lorem ipsum[^1] dolor sit amet, consectetur adipiscing elit.[^2] Result: Lorem ipsum[^1] dolor sit amet, consectetur adipiscing elit. ^2 Inserting the content The footnote content is also declared with a label, which must match the label used for the footnote reference. It can be inserted at an arbitrary position in the document and is always rendered at the bottom of the page. Furthermore, a backlink is automatically added to the footnote reference. on a single line Short statements can be written on the same line. Example: [^1]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Result: Jump to footnote at the bottom of the page [^1]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. on multiple lines Paragraphs should be written on the next line. As with all Markdown blocks, the content must be indented by four spaces. Example: [^2]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Jump to footnote at the bottom of the page","title":"Footnotes"},{"location":"extensions/footnotes/#footnotes","text":"Footnotes is another extension included in the standard Markdown library. As the name says, it adds the ability to add footnotes to your documentation.","title":"Footnotes"},{"location":"extensions/footnotes/#installation","text":"Add the following lines to your mkdocs.yml : markdown_extensions: - footnotes","title":"Installation"},{"location":"extensions/footnotes/#usage","text":"The markup for footnotes is similar to the standard Markdown markup for links. A reference is inserted in the text, which can then be defined at any point in the document.","title":"Usage"},{"location":"extensions/footnotes/#inserting-the-reference","text":"The footnote reference is enclosed in square brackets and starts with a caret, followed by an arbitrary label which may contain numeric identifiers [1, 2, 3, ...] or names [Granovetter et al. 1998]. The rendered references are always consecutive superscripted numbers. Example: Lorem ipsum[^1] dolor sit amet, consectetur adipiscing elit.[^2] Result: Lorem ipsum[^1] dolor sit amet, consectetur adipiscing elit. ^2","title":"Inserting the reference"},{"location":"extensions/footnotes/#inserting-the-content","text":"The footnote content is also declared with a label, which must match the label used for the footnote reference. It can be inserted at an arbitrary position in the document and is always rendered at the bottom of the page. Furthermore, a backlink is automatically added to the footnote reference.","title":"Inserting the content"},{"location":"extensions/footnotes/#on-a-single-line","text":"Short statements can be written on the same line. Example: [^1]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Result: Jump to footnote at the bottom of the page [^1]: Lorem ipsum dolor sit amet, consectetur adipiscing elit.","title":"on a single line"},{"location":"extensions/footnotes/#on-multiple-lines","text":"Paragraphs should be written on the next line. As with all Markdown blocks, the content must be indented by four spaces. Example: [^2]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Jump to footnote at the bottom of the page","title":"on multiple lines"},{"location":"extensions/metadata/","text":"Metadata The Metadata extension makes it possible to add metadata to a document which gives more control over the theme in a page-specific context. Installation Add the following lines to your mkdocs.yml : markdown_extensions: - meta Usage Metadata is written as a series of key-value pairs at the beginning of the Markdown document, delimited by a blank line which ends the metadata context. Naturally, the metadata is stripped from the document before rendering the actual page content and made available to the theme. Example: title: Lorem ipsum dolor sit amet description: Nullam urna elit, malesuada eget finibus ut, ac tortor. path: path/to/file source: file.js # Headline ... See the next section which covers the metadata that is supported by Material. Setting a hero text Material exposes a simple text-only page-local hero via Metadata, as you can see on the current page when you scroll to the top. It's as simple as: hero: Metadata enables hero teaser texts Linking sources When a document is related to a specific set of source files and the repo_url is defined inside the project's mkdocs.yml , the files can be linked using the source key: source: file.js The filename is appended to the repo_url set in your mkdocs.yml , but can be prefixed with a path to ensure correct path resolving: Example: path: tree/master/docs/extensions source: metadata.md Result: See the source section for the resulting output. Redirecting to another page It's sometimes necessary to move documents around in the navigation tree and redirect user from the old URL to the new one. The redirect meta-tag allows to create a redirection from the current document to the address specified in the tag. For instance, if your document contains: redirect: /new/url accessing that document's URL will automatically redirect to /new/url . Overrides Page title The page title can be overridden on a per-document level: title: Lorem ipsum dolor sit amet This will set the title tag inside the document head for the current page to the provided value. It will also override the default behavior of Material for MkDocs which appends the site title using a dash as a separator to the page title. Page description The page description can also be overridden on a per-document level: description: Nullam urna elit, malesuada eget finibus ut, ac tortor. This will set the meta tag containing the site description inside the document head for the current page to the provided value. Disqus As describe in the getting started guide , the Disqus comments section can be enabled on a per-document level: disqus: your-shortname Disqus can be disabled for a specific page by setting it to an empty value: disqus:","title":"Metadata"},{"location":"extensions/metadata/#metadata","text":"The Metadata extension makes it possible to add metadata to a document which gives more control over the theme in a page-specific context.","title":"Metadata"},{"location":"extensions/metadata/#installation","text":"Add the following lines to your mkdocs.yml : markdown_extensions: - meta","title":"Installation"},{"location":"extensions/metadata/#usage","text":"Metadata is written as a series of key-value pairs at the beginning of the Markdown document, delimited by a blank line which ends the metadata context. Naturally, the metadata is stripped from the document before rendering the actual page content and made available to the theme. Example: title: Lorem ipsum dolor sit amet description: Nullam urna elit, malesuada eget finibus ut, ac tortor. path: path/to/file source: file.js # Headline ... See the next section which covers the metadata that is supported by Material.","title":"Usage"},{"location":"extensions/metadata/#setting-a-hero-text","text":"Material exposes a simple text-only page-local hero via Metadata, as you can see on the current page when you scroll to the top. It's as simple as: hero: Metadata enables hero teaser texts","title":"Setting a hero text"},{"location":"extensions/metadata/#linking-sources","text":"When a document is related to a specific set of source files and the repo_url is defined inside the project's mkdocs.yml , the files can be linked using the source key: source: file.js The filename is appended to the repo_url set in your mkdocs.yml , but can be prefixed with a path to ensure correct path resolving: Example: path: tree/master/docs/extensions source: metadata.md Result: See the source section for the resulting output.","title":"Linking sources"},{"location":"extensions/metadata/#redirecting-to-another-page","text":"It's sometimes necessary to move documents around in the navigation tree and redirect user from the old URL to the new one. The redirect meta-tag allows to create a redirection from the current document to the address specified in the tag. For instance, if your document contains: redirect: /new/url accessing that document's URL will automatically redirect to /new/url .","title":"Redirecting to another page"},{"location":"extensions/metadata/#overrides","text":"","title":"Overrides"},{"location":"extensions/metadata/#page-title","text":"The page title can be overridden on a per-document level: title: Lorem ipsum dolor sit amet This will set the title tag inside the document head for the current page to the provided value. It will also override the default behavior of Material for MkDocs which appends the site title using a dash as a separator to the page title.","title":"Page title"},{"location":"extensions/metadata/#page-description","text":"The page description can also be overridden on a per-document level: description: Nullam urna elit, malesuada eget finibus ut, ac tortor. This will set the meta tag containing the site description inside the document head for the current page to the provided value.","title":"Page description"},{"location":"extensions/metadata/#disqus","text":"As describe in the getting started guide , the Disqus comments section can be enabled on a per-document level: disqus: your-shortname Disqus can be disabled for a specific page by setting it to an empty value: disqus:","title":"Disqus"},{"location":"extensions/permalinks/","text":"Permalinks Permalinks are a feature of the Table of Contents extension, which is part of the standard Markdown library. The extension inserts an anchor at the end of each headline, which makes it possible to directly link to a subpart of the document. Installation To enable permalinks, add the following to your mkdocs.yml : markdown_extensions: - toc: permalink: true This will add a link containing the paragraph symbol \u00b6 at the end of each headline (exactly like on the page you're currently viewing), which the Material theme will make appear on hover. In order to change the text of the permalink, a string can be passed, e.g.: markdown_extensions: - toc: permalink: Link Usage When enabled, permalinks are inserted automatically.","title":"Permalinks"},{"location":"extensions/permalinks/#permalinks","text":"Permalinks are a feature of the Table of Contents extension, which is part of the standard Markdown library. The extension inserts an anchor at the end of each headline, which makes it possible to directly link to a subpart of the document.","title":"Permalinks"},{"location":"extensions/permalinks/#installation","text":"To enable permalinks, add the following to your mkdocs.yml : markdown_extensions: - toc: permalink: true This will add a link containing the paragraph symbol \u00b6 at the end of each headline (exactly like on the page you're currently viewing), which the Material theme will make appear on hover. In order to change the text of the permalink, a string can be passed, e.g.: markdown_extensions: - toc: permalink: Link","title":"Installation"},{"location":"extensions/permalinks/#usage","text":"When enabled, permalinks are inserted automatically.","title":"Usage"},{"location":"extensions/pymdown/","text":"PyMdown Extensions PyMdown Extensions is a collection of Markdown extensions that add some great features to the standard Markdown library. For this reason, the installation of this package is highly recommended as it's well-integrated with the Material theme. Installation The PyMdown Extensions package can be installed with the following command: pip install pymdown-extensions The following list of extensions that are part of the PyMdown Extensions package are recommended to be used together with the Material theme: markdown_extensions: - pymdownx.arithmatex - pymdownx.betterem: smart_enable: all - pymdownx.caret - pymdownx.critic - pymdownx.details - pymdownx.emoji: emoji_generator: !!python/name:pymdownx.emoji.to_svg - pymdownx.inlinehilite - pymdownx.magiclink - pymdownx.mark - pymdownx.smartsymbols - pymdownx.superfences - pymdownx.tasklist: custom_checkbox: true - pymdownx.tilde Usage Arithmatex MathJax Arithmatex integrates Material with MathJax which parses block-style and inline equations written in TeX markup and outputs them in mathematical notation. See this thread for a short introduction and quick reference on how to write equations in TeX syntax. Besides activating the extension in the mkdocs.yml , the MathJax JavaScript runtime needs to be included. This must be done with additional JavaScript : extra_javascript: - 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML' If you want to override the default MathJax configuration, you can do this by adding another JavaScript file before the MathJax runtime in extra_javascript which contains your MathJax configuration, e.g.: window.MathJax = { tex2jax: { inlineMath: [ [\"\\\\(\",\"\\\\)\"] ], displayMath: [ [\"\\\\[\",\"\\\\]\"] ] }, TeX: { TagSide: \"right\", TagIndent: \".8em\", MultLineWidth: \"85%\", equationNumbers: { autoNumber: \"AMS\", }, unicode: { fonts: \"STIXGeneral,'Arial Unicode MS'\" } }, displayAlign: \"left\", showProcessingMessages: false, messageStyle: \"none\" }; In your mkdocs.yml , include it with: extra_javascript: - 'javascripts/extra.js' - 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML' Blocks Blocks are enclosed in :::tex $$...$$ which are placed on separate lines. Example: $$ \\frac{n!}{k!(n-k)!} = \\binom{n}{k} $$ Result: $$ \\frac{n!}{k!(n-k)!} = \\binom{n}{k} $$ Inline Inline equations need to be enclosed in :::tex $...$ : Example: Lorem ipsum dolor sit amet: $p(x|y) = \\frac{p(y|x)p(x)}{p(y)}$ Result: Lorem ipsum dolor sit amet: $p(x|y) = \\frac{p(y|x)p(x)}{p(y)}$ BetterEm BetterEm improves the handling of emphasis markup ( bold and italic ) within Markdown by providing a more sophisticated parser for better detecting start and end tokens. Read the documentation for usage notes . Caret Caret makes it possible to highlight ^^inserted text^^. The portion of text that should be marked as added must be enclosed in two carets ^^...^^ . Critic Critic implements Critic Markup , a Markdown extension that enables the tracking of changes (additions, deletions and comments) on documents. During compilation of the Markdown document, changes can be rendered (default), accepted or rejected. Text can be {--deleted--} and replacement text {++added++}. This can also be combined into {~~one~>a single~~} operation. {==Highlighting==} is also possible {>>and comments can be added inline<<}. {== Formatting can also be applied to blocks, by putting the opening and closing tags on separate lines and adding new lines between the tags and the content. ==} Details Details adds collapsible Admonition-style blocks which can contain arbitrary content using the HTML5 details and summary tags. Additionally, all Admonition qualifiers can be used, e.g. note , question , warning etc.: ??? question \"How many Prolog programmers does it take to change a lightbulb?\" Yes. Emoji Emoji adds the ability to insert a :shit:-load of emojis that we use in our daily lives. See the EmojiOne demo for a list of all available emojis. Happy scrolling :tada: !!! warning \"Legal disclaimer\" Material has no affiliation with [EmojiOne][15] which is released under [CC BY 4.0][16]. When including EmojiOne images or CSS, please read the [EmojiOne license][17] to ensure proper usage and attribution. InlineHilite InlineHilite adds support for inline code highlighting. It's useful for short snippets included within body copy, e.g. #!js var test = 0; and can be achived by prefixing inline code with a shebang and language identifier, e.g. #!js . MagicLink MagicLink detects links in Markdown and auto-generates the necessary markup, so no special syntax is required. It auto-links http[s]:// and ftp:// links, as well as references to email addresses. Mark Mark adds the ability to ==highlight text== like it was marked with a ==text marker==. The portion of text that should be highlighted must be enclosed in two equal signs ==...== . SmartSymbols SmartSymbols converts markup for special characters into their corresponding symbols, e.g. arrows (<--, -->, <-->), trademark and copyright symbols ((c), (tm), (r)) and fractions (1/2, 1/4, ...). SuperFences SuperFences provides the ability to nest code blocks under blockquotes, lists and other block elements, which the Fenced Code Blocks extension from the standard Markdown library doesn't parse correctly. SuperFences does also allow grouping code blocks with tabs . Tasklist Tasklist adds support for styled checkbox lists. This is useful for keeping track of tasks and showing what has been done and has yet to be done. Checkbox lists are like regular lists, but prefixed with [ ] for empty or [x] for filled checkboxes. Example: * [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit * [x] Nulla lobortis egestas semper * [x] Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est * [ ] Vestibulum convallis sit amet nisi a tincidunt * [x] In hac habitasse platea dictumst * [x] In scelerisque nibh non dolor mollis congue sed et metus * [x] Sed egestas felis quis elit dapibus, ac aliquet turpis mattis * [ ] Praesent sed risus massa * [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque * [ ] Nulla vel eros venenatis, imperdiet enim id, faucibus nisi Result: [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit [x] Nulla lobortis egestas semper [x] Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est [ ] Vestibulum convallis sit amet nisi a tincidunt [x] In hac habitasse platea dictumst [x] In scelerisque nibh non dolor mollis congue sed et metus [x] Sed egestas felis quis elit dapibus, ac aliquet turpis mattis [ ] Praesent sed risus massa [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque [ ] Nulla vel eros venenatis, imperdiet enim id, faucibus nisi Tilde Tilde provides an easy way to ~~strike through~~ cross out text. The portion of text that should be erased must be enclosed in two tildes ~~...~~ and the extension will take care of the rest.","title":"PyMdown Extensions"},{"location":"extensions/pymdown/#pymdown-extensions","text":"PyMdown Extensions is a collection of Markdown extensions that add some great features to the standard Markdown library. For this reason, the installation of this package is highly recommended as it's well-integrated with the Material theme.","title":"PyMdown Extensions"},{"location":"extensions/pymdown/#installation","text":"The PyMdown Extensions package can be installed with the following command: pip install pymdown-extensions The following list of extensions that are part of the PyMdown Extensions package are recommended to be used together with the Material theme: markdown_extensions: - pymdownx.arithmatex - pymdownx.betterem: smart_enable: all - pymdownx.caret - pymdownx.critic - pymdownx.details - pymdownx.emoji: emoji_generator: !!python/name:pymdownx.emoji.to_svg - pymdownx.inlinehilite - pymdownx.magiclink - pymdownx.mark - pymdownx.smartsymbols - pymdownx.superfences - pymdownx.tasklist: custom_checkbox: true - pymdownx.tilde","title":"Installation"},{"location":"extensions/pymdown/#usage","text":"","title":"Usage"},{"location":"extensions/pymdown/#arithmatex-mathjax","text":"Arithmatex integrates Material with MathJax which parses block-style and inline equations written in TeX markup and outputs them in mathematical notation. See this thread for a short introduction and quick reference on how to write equations in TeX syntax. Besides activating the extension in the mkdocs.yml , the MathJax JavaScript runtime needs to be included. This must be done with additional JavaScript : extra_javascript: - 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML' If you want to override the default MathJax configuration, you can do this by adding another JavaScript file before the MathJax runtime in extra_javascript which contains your MathJax configuration, e.g.: window.MathJax = { tex2jax: { inlineMath: [ [\"\\\\(\",\"\\\\)\"] ], displayMath: [ [\"\\\\[\",\"\\\\]\"] ] }, TeX: { TagSide: \"right\", TagIndent: \".8em\", MultLineWidth: \"85%\", equationNumbers: { autoNumber: \"AMS\", }, unicode: { fonts: \"STIXGeneral,'Arial Unicode MS'\" } }, displayAlign: \"left\", showProcessingMessages: false, messageStyle: \"none\" }; In your mkdocs.yml , include it with: extra_javascript: - 'javascripts/extra.js' - 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML'","title":"Arithmatex MathJax"},{"location":"extensions/pymdown/#blocks","text":"Blocks are enclosed in :::tex $$...$$ which are placed on separate lines. Example: $$ \\frac{n!}{k!(n-k)!} = \\binom{n}{k} $$ Result: $$ \\frac{n!}{k!(n-k)!} = \\binom{n}{k} $$","title":"Blocks"},{"location":"extensions/pymdown/#inline","text":"Inline equations need to be enclosed in :::tex $...$ : Example: Lorem ipsum dolor sit amet: $p(x|y) = \\frac{p(y|x)p(x)}{p(y)}$ Result: Lorem ipsum dolor sit amet: $p(x|y) = \\frac{p(y|x)p(x)}{p(y)}$","title":"Inline"},{"location":"extensions/pymdown/#betterem","text":"BetterEm improves the handling of emphasis markup ( bold and italic ) within Markdown by providing a more sophisticated parser for better detecting start and end tokens. Read the documentation for usage notes .","title":"BetterEm"},{"location":"extensions/pymdown/#caret","text":"Caret makes it possible to highlight ^^inserted text^^. The portion of text that should be marked as added must be enclosed in two carets ^^...^^ .","title":"Caret"},{"location":"extensions/pymdown/#critic","text":"Critic implements Critic Markup , a Markdown extension that enables the tracking of changes (additions, deletions and comments) on documents. During compilation of the Markdown document, changes can be rendered (default), accepted or rejected. Text can be {--deleted--} and replacement text {++added++}. This can also be combined into {~~one~>a single~~} operation. {==Highlighting==} is also possible {>>and comments can be added inline<<}. {== Formatting can also be applied to blocks, by putting the opening and closing tags on separate lines and adding new lines between the tags and the content. ==}","title":"Critic"},{"location":"extensions/pymdown/#details","text":"Details adds collapsible Admonition-style blocks which can contain arbitrary content using the HTML5 details and summary tags. Additionally, all Admonition qualifiers can be used, e.g. note , question , warning etc.: ??? question \"How many Prolog programmers does it take to change a lightbulb?\" Yes.","title":"Details"},{"location":"extensions/pymdown/#emoji","text":"Emoji adds the ability to insert a :shit:-load of emojis that we use in our daily lives. See the EmojiOne demo for a list of all available emojis. Happy scrolling :tada: !!! warning \"Legal disclaimer\" Material has no affiliation with [EmojiOne][15] which is released under [CC BY 4.0][16]. When including EmojiOne images or CSS, please read the [EmojiOne license][17] to ensure proper usage and attribution.","title":"Emoji"},{"location":"extensions/pymdown/#inlinehilite","text":"InlineHilite adds support for inline code highlighting. It's useful for short snippets included within body copy, e.g. #!js var test = 0; and can be achived by prefixing inline code with a shebang and language identifier, e.g. #!js .","title":"InlineHilite"},{"location":"extensions/pymdown/#magiclink","text":"MagicLink detects links in Markdown and auto-generates the necessary markup, so no special syntax is required. It auto-links http[s]:// and ftp:// links, as well as references to email addresses.","title":"MagicLink"},{"location":"extensions/pymdown/#mark","text":"Mark adds the ability to ==highlight text== like it was marked with a ==text marker==. The portion of text that should be highlighted must be enclosed in two equal signs ==...== .","title":"Mark"},{"location":"extensions/pymdown/#smartsymbols","text":"SmartSymbols converts markup for special characters into their corresponding symbols, e.g. arrows (<--, -->, <-->), trademark and copyright symbols ((c), (tm), (r)) and fractions (1/2, 1/4, ...).","title":"SmartSymbols"},{"location":"extensions/pymdown/#superfences","text":"SuperFences provides the ability to nest code blocks under blockquotes, lists and other block elements, which the Fenced Code Blocks extension from the standard Markdown library doesn't parse correctly. SuperFences does also allow grouping code blocks with tabs .","title":"SuperFences"},{"location":"extensions/pymdown/#tasklist","text":"Tasklist adds support for styled checkbox lists. This is useful for keeping track of tasks and showing what has been done and has yet to be done. Checkbox lists are like regular lists, but prefixed with [ ] for empty or [x] for filled checkboxes. Example: * [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit * [x] Nulla lobortis egestas semper * [x] Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est * [ ] Vestibulum convallis sit amet nisi a tincidunt * [x] In hac habitasse platea dictumst * [x] In scelerisque nibh non dolor mollis congue sed et metus * [x] Sed egestas felis quis elit dapibus, ac aliquet turpis mattis * [ ] Praesent sed risus massa * [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque * [ ] Nulla vel eros venenatis, imperdiet enim id, faucibus nisi Result: [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit [x] Nulla lobortis egestas semper [x] Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est [ ] Vestibulum convallis sit amet nisi a tincidunt [x] In hac habitasse platea dictumst [x] In scelerisque nibh non dolor mollis congue sed et metus [x] Sed egestas felis quis elit dapibus, ac aliquet turpis mattis [ ] Praesent sed risus massa [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque [ ] Nulla vel eros venenatis, imperdiet enim id, faucibus nisi","title":"Tasklist"},{"location":"extensions/pymdown/#tilde","text":"Tilde provides an easy way to ~~strike through~~ cross out text. The portion of text that should be erased must be enclosed in two tildes ~~...~~ and the extension will take care of the rest.","title":"Tilde"}]}